{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OO1ko1eXr46L",
        "outputId": "fa135d03-7f35-4ca0-d715-70f8f54d3c59"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.19.2)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.25.5)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.10.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.19.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.12.14)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtWfyGtDr7f_",
        "outputId": "96b4bcc1-5a30-4ff3-ebbb-80e29beed0fa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# Load biến môi trường từ file .env\n",
        "load_dotenv()\n",
        "\n",
        "# Lấy key từ biến môi trường\n",
        "wandb_api_key = os.getenv(\"WANDB_API_KEY\")\n",
        "print(wandb_api_key[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ghEn_Uqr84b",
        "outputId": "84e6ee33-d70e-43f2-bcf5-50700116df26"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "c8767\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "import os\n",
        "\n",
        "# Lấy API key từ biến môi trường và đăng nhập\n",
        "wandb.login(key=os.getenv(\"WANDB_API_KEY\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0lM9USFr-Su",
        "outputId": "e9b9c81f-2b0d-40e5-c42d-a90c22745869"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdoanngoccuong\u001b[0m (\u001b[33mdoanngoccuong_nh\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        },
        "id": "uCbMpJt2rh8d",
        "outputId": "c88d3753-af5d-4d3b-a08b-40113476c968"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250113_173544-e1s5eius</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/doanngoccuong_nh/bert-intent-classification/runs/e1s5eius' target=\"_blank\">denim-sun-68</a></strong> to <a href='https://wandb.ai/doanngoccuong_nh/bert-intent-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/doanngoccuong_nh/bert-intent-classification' target=\"_blank\">https://wandb.ai/doanngoccuong_nh/bert-intent-classification</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/doanngoccuong_nh/bert-intent-classification/runs/e1s5eius' target=\"_blank\">https://wandb.ai/doanngoccuong_nh/bert-intent-classification/runs/e1s5eius</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact last_model_epoch_30:v0, 419.95MB. 2 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   2 of 2 files downloaded.  \n",
            "Done. 0:0:1.9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in artifact_dir: ['tokenizer_config.json', 'special_tokens_map.json', 'model.safetensors', 'config.json', 'training_args.bin', 'vocab.txt', 'tokenizer.json']\n",
            "Config.json updated at /content/artifacts/last_model_epoch_30:v0/config.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer files saved to /content/artifacts/last_model_epoch_30:v0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /content/artifacts/last_model_epoch_30:v0 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded and running on device: cpu\n",
            "Question: What is the weather like today?\n",
            "Answer: \n",
            "Predicted class ID: 1\n",
            "Predicted label: intent_learn_more\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">denim-sun-68</strong> at: <a href='https://wandb.ai/doanngoccuong_nh/bert-intent-classification/runs/e1s5eius' target=\"_blank\">https://wandb.ai/doanngoccuong_nh/bert-intent-classification/runs/e1s5eius</a><br> View project at: <a href='https://wandb.ai/doanngoccuong_nh/bert-intent-classification' target=\"_blank\">https://wandb.ai/doanngoccuong_nh/bert-intent-classification</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250113_173544-e1s5eius/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import wandb\n",
        "\n",
        "# 1. Tải mô hình từ artifact trên WandB\n",
        "run = wandb.init(project=\"bert-intent-classification\")  # Tên dự án trong WandB\n",
        "artifact = run.use_artifact('doanngoccuong_nh/bert-intent-classification/last_model_epoch_30:v0', type='model')\n",
        "artifact_dir = artifact.download()\n",
        "print(\"Files in artifact_dir:\", os.listdir(artifact_dir))\n",
        "\n",
        "# Đường dẫn tệp cấu hình\n",
        "config_path = os.path.join(artifact_dir, \"config.json\")\n",
        "\n",
        "# Kiểm tra và cập nhật tệp config.json\n",
        "config = {\n",
        "    \"model_type\": \"bert\",\n",
        "    \"hidden_size\": 768,\n",
        "    \"num_attention_heads\": 12,\n",
        "    \"num_hidden_layers\": 12,\n",
        "    \"vocab_size\": 30522\n",
        "}\n",
        "with open(config_path, \"w\") as f:\n",
        "    json.dump(config, f, indent=4)\n",
        "print(f\"Config.json updated at {config_path}\")\n",
        "\n",
        "# Tải tokenizer từ mô hình gốc\n",
        "original_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Lưu các tệp cần thiết vào artifact_dir\n",
        "original_tokenizer.save_pretrained(artifact_dir)\n",
        "\n",
        "print(f\"Tokenizer files saved to {artifact_dir}\")\n",
        "\n",
        "# 4. Tải mô hình đã lưu và tokenizer\n",
        "model_path = artifact_dir  # Đường dẫn đến mô hình đã tải\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "# Chuyển mô hình sang chế độ đánh giá\n",
        "model.eval()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "print(f\"Model loaded and running on device: {device}\")\n",
        "\n",
        "# Bước 2: Chuẩn bị tokenizer và token hóa dữ liệu\n",
        "max_seq_length = 512\n",
        "\n",
        "def preprocess_input(question, answer, tokenizer, max_seq_length):\n",
        "    \"\"\"\n",
        "    Tiền xử lý dữ liệu đầu vào bằng cách ghép nối câu hỏi và câu trả lời với các token đặc biệt.\n",
        "    \"\"\"\n",
        "    input_text = f\"[CLS] {question.strip()} [SEP] {answer.strip()} [SEP]\"\n",
        "    inputs = tokenizer(\n",
        "        input_text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=max_seq_length\n",
        "    )\n",
        "    return inputs\n",
        "\n",
        "# 5. Xử lý đầu vào\n",
        "question = \"What is the weather like today?\"\n",
        "answer = \"\"\n",
        "inputs = preprocess_input(question, answer, tokenizer, max_seq_length)\n",
        "\n",
        "# Chuyển đầu vào sang thiết bị phù hợp\n",
        "inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "# 6. Thực hiện dự đoán\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)  # Truyền đầu vào qua mô hình\n",
        "    logits = outputs.logits  # Lấy logits từ đầu ra của mô hình\n",
        "    predicted_class = torch.argmax(logits, dim=1).item()  # Lấy nhãn dự đoán\n",
        "\n",
        "# 7. Mapping nhãn dự đoán sang tên nhãn\n",
        "label_mapping = {\n",
        "    0: \"intent_fallback\",\n",
        "    1: \"intent_learn_more\",\n",
        "    2: \"intent_negative\",\n",
        "    3: \"intent_neutral\",\n",
        "    4: \"intent_positive\",\n",
        "    5: \"silence\"\n",
        "}\n",
        "predicted_label = label_mapping.get(predicted_class, f\"Unknown (Class ID: {predicted_class})\")\n",
        "\n",
        "# 8. In kết quả dự đoán\n",
        "print(f\"Question: {question}\")\n",
        "print(f\"Answer: {answer}\")\n",
        "print(f\"Predicted class ID: {predicted_class}\")\n",
        "print(f\"Predicted label: {predicted_label}\")\n",
        "\n",
        "\n",
        "\n",
        "# Kết thúc phiên WandB\n",
        "wandb.finish()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bước 2: Chuẩn bị tokenizer và token hóa dữ liệu\n",
        "max_seq_length = 512\n",
        "\n",
        "def preprocess_input(question, answer, tokenizer, max_seq_length):\n",
        "    \"\"\"\n",
        "    Tiền xử lý dữ liệu đầu vào bằng cách ghép nối câu hỏi và câu trả lời với các token đặc biệt.\n",
        "    \"\"\"\n",
        "    input_text = f\"[CLS] {question.strip()} [SEP] {answer.strip()} [SEP]\"\n",
        "    inputs = tokenizer(\n",
        "        input_text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=max_seq_length\n",
        "    )\n",
        "    return inputs\n",
        "\n",
        "# 5. Xử lý đầu vào\n",
        "question = \"Cậu có thể kể tên một hành động bắt đầu bằng từ 'play' không?\"\n",
        "answer = \"\"\n",
        "inputs = preprocess_input(question, answer, tokenizer, max_seq_length)\n",
        "\n",
        "# Chuyển đầu vào sang thiết bị phù hợp\n",
        "inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "# 6. Thực hiện dự đoán\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)  # Truyền đầu vào qua mô hình\n",
        "    logits = outputs.logits  # Lấy logits từ đầu ra của mô hình\n",
        "    predicted_class = torch.argmax(logits, dim=1).item()  # Lấy nhãn dự đoán\n",
        "\n",
        "# 7. Mapping nhãn dự đoán sang tên nhãn\n",
        "label_mapping = {\n",
        "    0: \"intent_fallback\",\n",
        "    1: \"intent_learn_more\",\n",
        "    2: \"intent_negative\",\n",
        "    3: \"intent_neutral\",\n",
        "    4: \"intent_positive\",\n",
        "    5: \"silence\"\n",
        "}\n",
        "\n",
        "\n",
        "predicted_label = label_mapping.get(predicted_class, f\"Unknown (Class ID: {predicted_class})\")\n",
        "\n",
        "# 8. In kết quả dự đoán\n",
        "print(f\"Question: {question}\")\n",
        "print(f\"Answer: {answer}\")\n",
        "print(f\"Predicted class ID: {predicted_class}\")\n",
        "print(f\"Predicted label: {predicted_label}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tww_Q6gAuHyN",
        "outputId": "8c1700b1-984c-4d81-9384-1b271da38bdf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Cậu có thể kể tên một hành động bắt đầu bằng từ 'play' không?\n",
            "Answer: \n",
            "Predicted class ID: 1\n",
            "Predicted label: intent_learn_more\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jL1UI7Z-v78i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
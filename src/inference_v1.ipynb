{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Wandb"
      ],
      "metadata": {
        "id": "hlGH8X8T2-Xx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OO1ko1eXr46L",
        "outputId": "fa135d03-7f35-4ca0-d715-70f8f54d3c59"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.19.2)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.25.5)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.10.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.19.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.12.14)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtWfyGtDr7f_",
        "outputId": "96b4bcc1-5a30-4ff3-ebbb-80e29beed0fa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# Load biến môi trường từ file .env\n",
        "load_dotenv()\n",
        "\n",
        "# Lấy key từ biến môi trường\n",
        "wandb_api_key = os.getenv(\"WANDB_API_KEY\")\n",
        "print(wandb_api_key[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ghEn_Uqr84b",
        "outputId": "84e6ee33-d70e-43f2-bcf5-50700116df26"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "c8767\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "import os\n",
        "\n",
        "# Lấy API key từ biến môi trường và đăng nhập\n",
        "wandb.login(key=os.getenv(\"WANDB_API_KEY\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0lM9USFr-Su",
        "outputId": "e9b9c81f-2b0d-40e5-c42d-a90c22745869"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdoanngoccuong\u001b[0m (\u001b[33mdoanngoccuong_nh\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference"
      ],
      "metadata": {
        "id": "G1EseRGO3A32"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "uCbMpJt2rh8d",
        "outputId": "513a87a1-a5ea-405b-a798-c146cd70efd2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250113_180732-1i4i25um</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/doanngoccuong_nh/bert-intent-classification/runs/1i4i25um' target=\"_blank\">hopeful-night-74</a></strong> to <a href='https://wandb.ai/doanngoccuong_nh/bert-intent-classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/doanngoccuong_nh/bert-intent-classification' target=\"_blank\">https://wandb.ai/doanngoccuong_nh/bert-intent-classification</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/doanngoccuong_nh/bert-intent-classification/runs/1i4i25um' target=\"_blank\">https://wandb.ai/doanngoccuong_nh/bert-intent-classification/runs/1i4i25um</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact best_model_epoch_5:v0, 419.95MB. 2 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   2 of 2 files downloaded.  \n",
            "Done. 0:0:10.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in artifact_dir: ['model.safetensors', 'training_args.bin']\n",
            "Config.json updated at /content/artifacts/best_model_epoch_5:v0/config.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /content/artifacts/best_model_epoch_5:v0 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer files saved to /content/artifacts/best_model_epoch_5:v0\n",
            "Model loaded and running on device: cpu\n",
            "Question: What is the weather like today?\n",
            "Answer: \n",
            "Predicted class ID: 0\n",
            "Predicted label: intent_fallback\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">hopeful-night-74</strong> at: <a href='https://wandb.ai/doanngoccuong_nh/bert-intent-classification/runs/1i4i25um' target=\"_blank\">https://wandb.ai/doanngoccuong_nh/bert-intent-classification/runs/1i4i25um</a><br> View project at: <a href='https://wandb.ai/doanngoccuong_nh/bert-intent-classification' target=\"_blank\">https://wandb.ai/doanngoccuong_nh/bert-intent-classification</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250113_180732-1i4i25um/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import wandb\n",
        "\n",
        "# 1. Tải mô hình từ artifact trên WandB\n",
        "run = wandb.init(project=\"bert-intent-classification\")  # Tên dự án trong WandB\n",
        "artifact = run.use_artifact('doanngoccuong_nh/bert-intent-classification/best_model_epoch_5:v0', type='model')\n",
        "artifact_dir = artifact.download()\n",
        "print(\"Files in artifact_dir:\", os.listdir(artifact_dir))\n",
        "\n",
        "# Đường dẫn tệp cấu hình\n",
        "config_path = os.path.join(artifact_dir, \"config.json\")\n",
        "\n",
        "# Kiểm tra và cập nhật tệp config.json\n",
        "config = {\n",
        "    \"model_type\": \"bert\",\n",
        "    \"hidden_size\": 768,\n",
        "    \"num_attention_heads\": 12,\n",
        "    \"num_hidden_layers\": 12,\n",
        "    \"vocab_size\": 30522\n",
        "}\n",
        "with open(config_path, \"w\") as f:\n",
        "    json.dump(config, f, indent=4)\n",
        "print(f\"Config.json updated at {config_path}\")\n",
        "\n",
        "# Tải tokenizer từ mô hình gốc\n",
        "original_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Lưu các tệp cần thiết vào artifact_dir\n",
        "original_tokenizer.save_pretrained(artifact_dir)\n",
        "\n",
        "print(f\"Tokenizer files saved to {artifact_dir}\")\n",
        "\n",
        "# 4. Tải mô hình đã lưu và tokenizer\n",
        "model_path = artifact_dir  # Đường dẫn đến mô hình đã tải\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "# Chuyển mô hình sang chế độ đánh giá\n",
        "model.eval()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "print(f\"Model loaded and running on device: {device}\")\n",
        "\n",
        "# Bước 2: Chuẩn bị tokenizer và token hóa dữ liệu\n",
        "max_seq_length = 512\n",
        "\n",
        "def preprocess_input(question, answer, tokenizer, max_seq_length):\n",
        "    \"\"\"\n",
        "    Tiền xử lý dữ liệu đầu vào bằng cách ghép nối câu hỏi và câu trả lời với các token đặc biệt.\n",
        "    \"\"\"\n",
        "    input_text = f\"[CLS] {question.strip()} [SEP] {answer.strip()} [SEP]\"\n",
        "    inputs = tokenizer(\n",
        "        input_text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=max_seq_length\n",
        "    )\n",
        "    return inputs\n",
        "\n",
        "# 5. Xử lý đầu vào\n",
        "question = \"What is the weather like today?\"\n",
        "answer = \"\"\n",
        "inputs = preprocess_input(question, answer, tokenizer, max_seq_length)\n",
        "\n",
        "# Chuyển đầu vào sang thiết bị phù hợp\n",
        "inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "# 6. Thực hiện dự đoán\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)  # Truyền đầu vào qua mô hình\n",
        "    logits = outputs.logits  # Lấy logits từ đầu ra của mô hình\n",
        "    predicted_class = torch.argmax(logits, dim=1).item()  # Lấy nhãn dự đoán\n",
        "\n",
        "# 7. Mapping nhãn dự đoán sang tên nhãn\n",
        "label_mapping = {\n",
        "    0: \"intent_fallback\",\n",
        "    1: \"intent_learn_more\",\n",
        "    2: \"intent_negative\",\n",
        "    3: \"intent_neutral\",\n",
        "    4: \"intent_positive\",\n",
        "    5: \"silence\"\n",
        "}\n",
        "predicted_label = label_mapping.get(predicted_class, f\"Unknown (Class ID: {predicted_class})\")\n",
        "\n",
        "# 8. In kết quả dự đoán\n",
        "print(f\"Question: {question}\")\n",
        "print(f\"Answer: {answer}\")\n",
        "print(f\"Predicted class ID: {predicted_class}\")\n",
        "print(f\"Predicted label: {predicted_label}\")\n",
        "\n",
        "\n",
        "\n",
        "# Kết thúc phiên WandB\n",
        "wandb.finish()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir(artifact_dir))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2Vdh-juxeE1",
        "outputId": "cbe19855-7ab0-407b-fd78-d7a1f07e5664"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['tokenizer_config.json', 'special_tokens_map.json', 'model.safetensors', 'config.json', 'training_args.bin', 'vocab.txt', 'tokenizer.json']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Đánh giá hàng loạt"
      ],
      "metadata": {
        "id": "B91cBzNy3QIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import wandb\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Tải mô hình từ artifact trên WandB\n",
        "run = wandb.init(project=\"bert-intent-classification\")  # Tên dự án trong WandB\n",
        "artifact = run.use_artifact('doanngoccuong_nh/bert-intent-classification/best_model_epoch_4:v0', type='model')\n",
        "artifact_dir = artifact.download()\n",
        "print(\"Files in artifact_dir:\", os.listdir(artifact_dir))\n",
        "\n",
        "# Đường dẫn tệp cấu hình\n",
        "config_path = os.path.join(artifact_dir, \"config.json\")\n",
        "\n",
        "# Kiểm tra và cập nhật tệp config.json\n",
        "config = {\n",
        "    \"model_type\": \"bert\",\n",
        "    \"hidden_size\": 768,\n",
        "    \"num_attention_heads\": 12,\n",
        "    \"num_hidden_layers\": 12,\n",
        "    \"vocab_size\": 30522\n",
        "}\n",
        "with open(config_path, \"w\") as f:\n",
        "    json.dump(config, f, indent=4)\n",
        "print(f\"Config.json updated at {config_path}\")\n",
        "\n",
        "# Tải tokenizer từ mô hình gốc\n",
        "original_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Lưu các tệp cần thiết vào artifact_dir\n",
        "original_tokenizer.save_pretrained(artifact_dir)\n",
        "\n",
        "print(f\"Tokenizer files saved to {artifact_dir}\")\n",
        "\n",
        "# 4. Tải mô hình đã lưu và tokenizer\n",
        "model_path = artifact_dir  # Đường dẫn đến mô hình đã tải\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "# Chuyển mô hình sang chế độ đánh giá\n",
        "model.eval()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "print(f\"Model loaded and running on device: {device}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Bước 2: Chuẩn bị tokenizer và token hóa dữ liệu\n",
        "max_seq_length = 512\n",
        "\n",
        "def preprocess_input(question, answer, tokenizer, max_seq_length):\n",
        "    \"\"\"\n",
        "    Tiền xử lý dữ liệu đầu vào bằng cách ghép nối câu hỏi và câu trả lời với các token đặc biệt.\n",
        "    \"\"\"\n",
        "    input_text = f\"[CLS] {question.strip()} [SEP] {answer.strip()} [SEP]\"\n",
        "    inputs = tokenizer(\n",
        "        input_text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=max_seq_length\n",
        "    )\n",
        "    return inputs\n",
        "\n",
        "# 5. Đọc dữ liệu từ file Excel\n",
        "data_file = \"/content/processed_data_example_v2.xlsx\"\n",
        "data = pd.read_excel(data_file)\n",
        "\n",
        "# Kiểm tra dữ liệu\n",
        "print(\"Sample data:\")\n",
        "print(data.head())\n",
        "\n",
        "# 6. Khởi tạo biến lưu kết quả\n",
        "results = []\n",
        "correct_predictions = 0\n",
        "\n",
        "def map_label(pred_class, label_mapping):\n",
        "    return label_mapping.get(pred_class, f\"Unknown (Class ID: {pred_class})\")\n",
        "\n",
        "# Cập nhật label_mapping từ thông tin huấn luyện\n",
        "label_mapping = {\n",
        "    0: \"intent_fallback\",\n",
        "    1: \"intent_learn_more\",\n",
        "    2: \"intent_negative\",\n",
        "    3: \"intent_neutral\",\n",
        "    4: \"intent_positive\",\n",
        "    5: \"silence\"\n",
        "}\n",
        "\n",
        "# 7. Thực hiện inference trên từng dòng dữ liệu\n",
        "import os\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import torch\n",
        "\n",
        "def process_and_update_file(input_file, output_file, model, tokenizer, label_mapping, max_seq_length, device):\n",
        "    \"\"\"\n",
        "    Processes an input Excel file, performs inference, and updates the file with predicted results.\n",
        "\n",
        "    Args:\n",
        "        input_file (str): Path to the input Excel file.\n",
        "        output_file (str): Path to the output Excel file.\n",
        "        model: The trained model for inference.\n",
        "        tokenizer: Tokenizer for preprocessing.\n",
        "        label_mapping (dict): Mapping from class index to label.\n",
        "        max_seq_length (int): Maximum sequence length for the tokenizer.\n",
        "        device: PyTorch device (e.g., 'cpu' or 'cuda').\n",
        "    \"\"\"\n",
        "    # Sao chép file gốc nếu file output chưa tồn tại\n",
        "    if not os.path.exists(output_file):\n",
        "        shutil.copy(input_file, output_file)\n",
        "        print(f\"File copied from {input_file} to {output_file}\")\n",
        "\n",
        "    # Đọc dữ liệu từ file output\n",
        "    data = pd.read_excel(output_file)\n",
        "\n",
        "    # Xử lý inference và thêm cột mới\n",
        "    results = []\n",
        "    correct_predictions = 0\n",
        "\n",
        "    for idx, row in data.iterrows():\n",
        "        question = row[\"question\"]\n",
        "        answer = row[\"answer\"] if not pd.isna(row[\"answer\"]) else \"\"\n",
        "        true_intent = row[\"intent\"]\n",
        "\n",
        "        # Tiền xử lý đầu vào\n",
        "        inputs = preprocess_input(question, answer, tokenizer, max_seq_length)\n",
        "        inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "        # Thực hiện dự đoán\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            logits = outputs.logits\n",
        "            predicted_class = torch.argmax(logits, dim=1).item()\n",
        "            predicted_label = map_label(predicted_class, label_mapping)\n",
        "\n",
        "        # Kiểm tra đúng sai\n",
        "        is_correct = (predicted_label == true_intent)\n",
        "        if is_correct:\n",
        "            correct_predictions += 1\n",
        "\n",
        "        # Lưu kết quả\n",
        "        results.append({\n",
        "            \"predicted_intent\": predicted_label,\n",
        "            \"is_correct\": is_correct\n",
        "        })\n",
        "\n",
        "    # Tạo DataFrame từ kết quả\n",
        "    results_df = pd.DataFrame(results)\n",
        "\n",
        "    # Thêm cột vào DataFrame ban đầu\n",
        "    data[\"predicted_intent\"] = results_df[\"predicted_intent\"]\n",
        "    data[\"is_correct\"] = results_df[\"is_correct\"]\n",
        "\n",
        "    # Ghi kết quả trở lại file Excel\n",
        "    with pd.ExcelWriter(output_file, engine=\"openpyxl\", mode=\"w\") as writer:\n",
        "        data.to_excel(writer, index=False)\n",
        "\n",
        "    # Tính accuracy\n",
        "    accuracy = correct_predictions / len(data)\n",
        "    print(f\"Accuracy: {accuracy:.2%}\")\n",
        "    print(f\"Evaluation results saved to {output_file}\")\n",
        "# Định nghĩa các tham số cần thiết\n",
        "input_file = \"/content/processed_data_example_v2.xlsx\"\n",
        "output_file = \"evaluation_results.xlsx\"\n",
        "# model = ...  # Model đã huấn luyện\n",
        "# tokenizer = ...  # Tokenizer tương ứng\n",
        "# label_mapping = {0: \"intent_A\", 1: \"intent_B\", 2: \"intent_C\"}  # Mapping nhãn\n",
        "# max_seq_length = 128  # Độ dài tối đa\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Gọi hàm để xử lý và cập nhật file\n",
        "process_and_update_file(input_file, output_file, model, tokenizer, label_mapping, max_seq_length, device)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "id": "tww_Q6gAuHyN",
        "outputId": "e49984df-802f-4a3d-976d-aafe140a310e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact best_model_epoch_4:v0, 419.95MB. 2 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   2 of 2 files downloaded.  \n",
            "Done. 0:0:1.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in artifact_dir: ['tokenizer_config.json', 'special_tokens_map.json', 'model.safetensors', 'config.json', 'training_args.bin', 'vocab.txt', 'tokenizer.json']\n",
            "Config.json updated at /content/artifacts/best_model_epoch_4:v0/config.json\n",
            "Tokenizer files saved to /content/artifacts/best_model_epoch_4:v0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /content/artifacts/best_model_epoch_4:v0 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded and running on device: cpu\n",
            "Sample data:\n",
            "                                            question  \\\n",
            "0  Cậu có thể kể tên một số hành động bắt đầu bằn...   \n",
            "1                Cậu có biết thêm từ nào khác không?   \n",
            "2                  Cậu có thích chơi trò chơi không?   \n",
            "3                       Cậu có muốn chơi thêm không?   \n",
            "4                              Cậu có thấy dễ không?   \n",
            "\n",
            "                                              answer           intent  \n",
            "0  Tớ có thể nói 'play football' và 'play basketb...  intent_positive  \n",
            "1                          Tớ biết 'play games' nữa.  intent_positive  \n",
            "2                  Tớ không thích chơi trò chơi lắm.  intent_negative  \n",
            "3                       Tớ không muốn chơi thêm đâu.  intent_negative  \n",
            "4                   Tớ không chắc lắm, có thể là dễ.   intent_neutral  \n",
            "File copied from /content/processed_data_example_v2.xlsx to evaluation_results.xlsx\n",
            "Accuracy: 16.67%\n",
            "Evaluation results saved to evaluation_results.xlsx\n"
          ]
        }
      ]
    }
  ]
}
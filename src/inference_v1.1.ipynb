{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Wandb"
      ],
      "metadata": {
        "id": "hlGH8X8T2-Xx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OO1ko1eXr46L",
        "outputId": "e27d134f-550b-448d-de0c-73aaf7dc8fe6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.19.1)\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.19.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.25.5)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.10.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.19.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=2.6->wandb) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.12.14)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Downloading wandb-0.19.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m82.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wandb\n",
            "  Attempting uninstall: wandb\n",
            "    Found existing installation: wandb 0.19.1\n",
            "    Uninstalling wandb-0.19.1:\n",
            "      Successfully uninstalled wandb-0.19.1\n",
            "Successfully installed wandb-0.19.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtWfyGtDr7f_",
        "outputId": "c6c342d7-69d4-4e1b-a77c-1f32d287e08b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "# Load biến môi trường từ file .env\n",
        "load_dotenv()\n",
        "\n",
        "# Lấy key từ biến môi trường\n",
        "wandb_api_key = os.getenv(\"WANDB_API_KEY\")\n",
        "print(wandb_api_key[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ghEn_Uqr84b",
        "outputId": "a2fd9a35-ac22-450d-b3e9-e819b613ab91"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "c8767\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "import os\n",
        "\n",
        "# Lấy API key từ biến môi trường và đăng nhập\n",
        "wandb.login(key=wandb_api_key)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0lM9USFr-Su",
        "outputId": "5f450094-6992-4e8e-da32-5497d3d5b2aa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdoanngoccuong\u001b[0m (\u001b[33mdoanngoccuong_nh\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference"
      ],
      "metadata": {
        "id": "G1EseRGO3A32"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bug:\n",
        "```bash\n",
        "model_path = artifact_dir  # Đường dẫn đến mô hình đã tải\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "```\n",
        "\n",
        "Sửa thành\n",
        "```bash\n",
        "# Khởi tạo mô hình trống\n",
        "from safetensors.torch import load_file\n",
        "model = BERTIntentClassification(model_name=\"bert-base-uncased\", num_classes=6)\n",
        "weights_path = os.path.join(artifact_dir, \"model.safetensors\") # Đường dẫn đến tệp `model.safetensors`\n",
        "state_dict = load_file(weights_path) # Tải trọng số vào mô hình\n",
        "model.load_state_dict(state_dict)\n",
        "model.eval()\n",
        "\n",
        "\n",
        "# Chuyển mô hình sang chế độ đánh giá\n",
        "model.eval()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "print(f\"Model loaded and running on device: {device}\")\n",
        "```"
      ],
      "metadata": {
        "id": "TMovpFG2LZhQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Đánh giá hàng loạt"
      ],
      "metadata": {
        "id": "B91cBzNy3QIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, TrainingArguments, Trainer, AutoModel\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "from typing import List\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FhbVxfoXFl9c"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class BERTIntentClassification(nn.Module):\n",
        "\n",
        "\n",
        "    def __init__(self, model_name=\"bert-base-uncased\", num_classes=10, dropout_rate=0.1, cache_dir = \"huggingface\"):\n",
        "        super(BERTIntentClassification, self).__init__()\n",
        "        self.bert = AutoModel.from_pretrained(model_name, cache_dir = cache_dir)\n",
        "        # Get BERT hidden size\n",
        "        hidden_size = self.bert.config.hidden_size\n",
        "        self.ffnn = nn.Sequential(\n",
        "            nn.Linear(hidden_size, hidden_size),\n",
        "            nn.LayerNorm(hidden_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(hidden_size, num_classes)\n",
        "        )\n",
        "\n",
        "\n",
        "    def freeze_bert(self):\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "\n",
        "    def get_pooling(self, hidden_state, attention_mask):\n",
        "        \"\"\"\n",
        "        Get mean pooled representation from BERT hidden states\n",
        "        Args:\n",
        "            hidden_state: BERT output containing hidden states\n",
        "        Returns:\n",
        "            pooled_output: Mean pooled representation of the sequence\n",
        "        \"\"\"\n",
        "        # Get last hidden state\n",
        "        last_hidden_state = hidden_state.last_hidden_state  # Shape: [batch_size, seq_len, hidden_size]\n",
        "\n",
        "        if attention_mask is not None:\n",
        "            # Expand attention mask to match hidden state dimensions\n",
        "            attention_mask = attention_mask.unsqueeze(-1)  # [batch_size, seq_len, 1]\n",
        "\n",
        "            # Mask out padding tokens\n",
        "            masked_hidden = last_hidden_state * attention_mask\n",
        "\n",
        "            # Calculate mean (sum / number of actual tokens)\n",
        "            sum_hidden = torch.sum(masked_hidden, dim=1)  # [batch_size, hidden_size]\n",
        "            count_tokens = torch.sum(attention_mask, dim=1)  # [batch_size, 1]\n",
        "            pooled_output = sum_hidden / count_tokens\n",
        "        else:\n",
        "            # If no attention mask, simply take mean of all tokens\n",
        "            pooled_output = torch.mean(last_hidden_state, dim=1)\n",
        "\n",
        "        return pooled_output\n",
        "\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, **kwargs):\n",
        "        \"\"\"\n",
        "        Forward pass of the model\n",
        "        Args:\n",
        "            input_ids: Input token IDs\n",
        "            attention_mask: Attention mask for padding\n",
        "        Returns:\n",
        "            logits: Raw logits for each class\n",
        "        \"\"\"\n",
        "        # Get BERT hidden states\n",
        "        hidden_state = self.bert(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "        )\n",
        "\n",
        "        # Get pooled representation\n",
        "        hidden_state_pooling = self.get_pooling(hidden_state=hidden_state, attention_mask=attention_mask)\n",
        "\n",
        "        # Pass through FFNN classifier\n",
        "        logits = self.ffnn(hidden_state_pooling)\n",
        "\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "HWRfdcybEeMe"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
        "import wandb\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "\n",
        "\n",
        "\n",
        "# 1. Tải mô hình từ artifact trên WandB\n",
        "run = wandb.init(project=\"bert-intent-classification\")  # Tên dự án trong WandB\n",
        "artifact = run.use_artifact('doanngoccuong_nh/bertIntentClassification/best_model_epoch_30:v0', type='model')\n",
        "artifact_dir = artifact.download()\n",
        "print(\"Files in artifact_dir:\", os.listdir(artifact_dir))\n",
        "\n",
        "# Đường dẫn tệp cấu hình\n",
        "config_path = os.path.join(artifact_dir, \"config.json\")\n",
        "\n",
        "# Kiểm tra và cập nhật tệp config.json\n",
        "config = {\n",
        "    \"model_type\": \"bert\",\n",
        "    \"hidden_size\": 768,\n",
        "    \"num_attention_heads\": 12,\n",
        "    \"num_hidden_layers\": 12,\n",
        "    \"vocab_size\": 30522\n",
        "}\n",
        "with open(config_path, \"w\") as f:\n",
        "    json.dump(config, f, indent=4)\n",
        "print(f\"Config.json updated at {config_path}\")\n",
        "\n",
        "\n",
        "# 2. Create config.json if not available\n",
        "config = AutoConfig.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Tải tokenizer từ mô hình gốc\n",
        "original_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Lưu các tệp cần thiết vào artifact_dir\n",
        "original_tokenizer.save_pretrained(artifact_dir)\n",
        "\n",
        "print(f\"Tokenizer files saved to {artifact_dir}\")\n",
        "\n",
        "# 4. Tải mô hình đã lưu và tokenizer\n",
        "model_path = artifact_dir  # Đường dẫn đến mô hình đã tải\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "# model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "\n",
        "\n",
        "# Khởi tạo mô hình trống\n",
        "from safetensors.torch import load_file\n",
        "model = BERTIntentClassification(model_name=\"bert-base-uncased\", num_classes=6)\n",
        "weights_path = os.path.join(artifact_dir, \"model.safetensors\") # Đường dẫn đến tệp `model.safetensors`\n",
        "state_dict = load_file(weights_path) # Tải trọng số vào mô hình\n",
        "model.load_state_dict(state_dict)\n",
        "model.eval()\n",
        "\n",
        "\n",
        "# Chuyển mô hình sang chế độ đánh giá\n",
        "model.eval()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "print(f\"Model loaded and running on device: {device}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Bước 2: Chuẩn bị tokenizer và token hóa dữ liệu\n",
        "max_seq_length = 512\n",
        "\n",
        "def preprocess_input(question, answer, tokenizer, max_seq_length):\n",
        "    \"\"\"\n",
        "    Tiền xử lý dữ liệu đầu vào bằng cách ghép nối câu hỏi và câu trả lời với các token đặc biệt.\n",
        "    \"\"\"\n",
        "    input_text = f\"[CLS] {question.strip()} [SEP] {answer.strip()} [SEP]\"\n",
        "    inputs = tokenizer(\n",
        "        input_text,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=max_seq_length\n",
        "    )\n",
        "    return inputs\n",
        "\n",
        "# 6. Khởi tạo biến lưu kết quả\n",
        "results = []\n",
        "correct_predictions = 0\n",
        "\n",
        "def map_label(pred_class, label_mapping):\n",
        "    return label_mapping.get(pred_class, f\"Unknown (Class ID: {pred_class})\")\n",
        "\n",
        "# Cập nhật label_mapping từ thông tin huấn luyện\n",
        "label_mapping = {\n",
        "    0: \"intent_fallback\",\n",
        "    1: \"intent_learn_more\",\n",
        "    2: \"intent_negative\",\n",
        "    3: \"intent_neutral\",\n",
        "    4: \"intent_positive\",\n",
        "    5: \"silence\"\n",
        "}\n",
        "\n",
        "# 7. Thực hiện inference trên từng dòng dữ liệu\n",
        "import os\n",
        "import pandas as pd\n",
        "import shutil\n",
        "import torch\n",
        "\n",
        "def process_and_update_file(input_file, output_file, model, tokenizer, label_mapping, max_seq_length, device, num_rows=None):\n",
        "    \"\"\"\n",
        "    Processes an input Excel file, performs inference, and updates the file with predicted results.\n",
        "\n",
        "    Args:\n",
        "        input_file (str): Path to the input Excel file.\n",
        "        output_file (str): Path to the output Excel file.\n",
        "        model: The trained model for inference.\n",
        "        tokenizer: Tokenizer for preprocessing.\n",
        "        label_mapping (dict): Mapping from class index to label.\n",
        "        max_seq_length (int): Maximum sequence length for the tokenizer.\n",
        "        device: PyTorch device (e.g., 'cpu' or 'cuda').\n",
        "        num_rows (int, optional): Number of rows to process. Default is None (process all rows).\n",
        "    \"\"\"\n",
        "    # Sao chép file gốc nếu file output chưa tồn tại\n",
        "    if not os.path.exists(output_file):\n",
        "        shutil.copy(input_file, output_file)\n",
        "        print(f\"File copied from {input_file} to {output_file}\")\n",
        "\n",
        "    # Đọc dữ liệu từ file output\n",
        "    data = pd.read_excel(output_file)\n",
        "\n",
        "    # Giới hạn số dòng nếu cần\n",
        "    if num_rows is not None:\n",
        "        data = data.head(num_rows)\n",
        "        print(f\"Processing only the first {num_rows} rows.\")\n",
        "\n",
        "    # Xử lý inference và thêm cột mới\n",
        "    results = []\n",
        "    correct_predictions = 0\n",
        "\n",
        "\n",
        "\n",
        "    for idx, row in data.iterrows():\n",
        "        question = row[\"robot\"]\n",
        "        answer = row[\"user_answer\"] if not pd.isna(row[\"user_answer\"]) else \"\"\n",
        "        true_intent = row[\"user_intent\"]\n",
        "\n",
        "        # Tiền xử lý đầu vào\n",
        "        inputs = preprocess_input(question, answer, tokenizer, max_seq_length)\n",
        "        inputs = {key: value.to(device) for key, value in inputs.items()}\n",
        "\n",
        "        # Thực hiện dự đoán\n",
        "        start_time = time.time()\n",
        "        with torch.no_grad():\n",
        "            logits = model(**inputs)  # Custom model directly returns logits\n",
        "            predicted_class = torch.argmax(logits, dim=1).item()\n",
        "            predicted_label = map_label(predicted_class, label_mapping)\n",
        "        end_time = time.time()\n",
        "\n",
        "        # Calculate response time\n",
        "        response_time = end_time - start_time\n",
        "\n",
        "        # Kiểm tra đúng sai\n",
        "        is_correct = (predicted_label == true_intent)\n",
        "        if is_correct:\n",
        "            correct_predictions += 1\n",
        "\n",
        "        # Lưu kết quả\n",
        "        results.append({\n",
        "            \"predicted_intent\": predicted_label,\n",
        "            \"is_correct\": is_correct,\n",
        "            \"model_response_time\": response_time\n",
        "        })\n",
        "\n",
        "        print(f\"Question: {question}\")\n",
        "        print(f\"Answer: {answer}\")\n",
        "        print(f\"Inputs: {inputs}\")\n",
        "        print(f\"Logits: {logits}\")\n",
        "        print(f\"Predicted class: {predicted_class}\")\n",
        "        print(f\"Predicted label: {predicted_label}\")\n",
        "\n",
        "    # Tạo DataFrame từ kết quả\n",
        "    results_df = pd.DataFrame(results)\n",
        "\n",
        "    # Thêm cột vào DataFrame ban đầu\n",
        "    data[\"predicted_intent\"] = results_df[\"predicted_intent\"]\n",
        "    data[\"is_correct\"] = results_df[\"is_correct\"]\n",
        "    data[\"model_response_time\"] = results_df[\"model_response_time\"]\n",
        "\n",
        "    # Ghi kết quả trở lại file Excel\n",
        "    with pd.ExcelWriter(output_file, engine=\"openpyxl\", mode=\"w\") as writer:\n",
        "        data.to_excel(writer, index=False)\n",
        "\n",
        "    # Tính accuracy\n",
        "    accuracy = correct_predictions / len(data)\n",
        "    print(f\"Accuracy: {accuracy:.2%}\")\n",
        "    print(f\"Evaluation results saved to {output_file}\")\n",
        "\n",
        "# Định nghĩa các tham số cần thiết\n",
        "input_file = \"/content/processed_data_example_v4_15000Data.xlsx\"\n",
        "output_file = \"evaluation_results.xlsx\"\n",
        "num_rows = 30  # Số lượng dòng muốn đánh giá\n",
        "# model = ...  # Model đã huấn luyện\n",
        "# tokenizer = ...  # Tokenizer tương ứng\n",
        "# label_mapping = {0: \"intent_A\", 1: \"intent_B\", 2: \"intent_C\"}  # Mapping nhãn\n",
        "# max_seq_length = 128  # Độ dài tối đa\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Gọi hàm để xử lý và cập nhật file\n",
        "# Định nghĩa các tham số cần thiết\n",
        "\n",
        "\n",
        "# Gọi hàm để xử lý và giới hạn số dòng\n",
        "process_and_update_file(input_file, output_file, model, tokenizer, label_mapping, max_seq_length, device, num_rows=num_rows)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xYym83_-8Gd7",
        "outputId": "7d3e8433-9461-48db-eb55-140c6c26f7c8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact best_model_epoch_30:v0, 419.95MB. 2 files... \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   2 of 2 files downloaded.  \n",
            "Done. 0:0:1.6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in artifact_dir: ['model.safetensors', 'vocab.txt', 'tokenizer_config.json', 'special_tokens_map.json', 'training_args.bin', 'tokenizer.json', 'config.json']\n",
            "Config.json updated at /content/artifacts/best_model_epoch_30:v0/config.json\n",
            "Tokenizer files saved to /content/artifacts/best_model_epoch_30:v0\n",
            "Model loaded and running on device: cuda\n",
            "Processing only the first 30 rows.\n",
            "Question: Được rồi, bây giờ chúng ta sẽ chơi một trò chơi! Hãy kể tên nhiều từ thuộc cùng 1 chủ đề nhé. Chủ đề lần này là hành động bắt đầu bằng từ \"eat food\". Tớ ví dụ nhé, \"eat pizza\", đến lượt cậu nhé\n",
            "Answer: Tớ ăn cơm.\n",
            "Inputs: {'input_ids': tensor([[  101,   101,  1102, 19098,  2278, 25223,  1010,  3016, 21025,  2080,\n",
            "         15972, 11937,  7367, 18151,  9587,  2102, 19817,  2080, 18151,   999,\n",
            "         10974, 17710,  2702, 18699, 17301, 10722, 16215, 19098,  2278, 12731,\n",
            "          3070,  1015, 14684,  1102,  2063, 18699,  2063,  1012, 14684,  1102,\n",
            "          2063, 17595, 29349,  2474,  7658,  2232,  1102,  5063,  7151,  1102,\n",
            "          4887,  9748, 10722,  1000,  4521,  2833,  1000,  1012,  2000,  6819,\n",
            "          4241, 18699,  2063,  1010,  1000,  4521, 10733,  1000,  1010,  1102,\n",
            "          2368, 11320,  4140,  6187,  2226, 18699,  2063,   102,  2000,  2019,\n",
            "          4012,  1012,   102,   102]], device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n",
            "Logits: tensor([[-2.4399, -1.0995, -1.4934, -0.9528,  5.2473, -4.7549]],\n",
            "       device='cuda:0')\n",
            "Predicted class: 4\n",
            "Predicted label: intent_positive\n",
            "Question: Tốt lắm! Cậu có thể kể thêm từ nào khác không?\n",
            "Answer: Tớ ăn bánh mì.\n",
            "Inputs: {'input_ids': tensor([[  101,   101,  2000,  2102, 16983,   999,  6187,  2226,  2522,  1996,\n",
            "         17710,  2068, 10722,  6583,  2080,  1047,  3270,  2278,  1047, 19991,\n",
            "          1029,   102,  2000,  2019,  7221,  2232,  2771,  1012,   102,   102]],\n",
            "       device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1]], device='cuda:0')}\n",
            "Logits: tensor([[-3.4638,  0.3187, -2.8811,  0.1605,  4.3471, -1.4070]],\n",
            "       device='cuda:0')\n",
            "Predicted class: 4\n",
            "Predicted label: intent_positive\n",
            "Question: Cậu có biết thêm từ nào khác không?\n",
            "Answer: Tớ không biết nữa.\n",
            "Inputs: {'input_ids': tensor([[  101,   101,  6187,  2226,  2522, 12170,  3388,  2068, 10722,  6583,\n",
            "          2080,  1047,  3270,  2278,  1047, 19991,  1029,   102,  2000,  1047,\n",
            "         19991, 12170,  3388, 16371,  2050,  1012,   102,   102]],\n",
            "       device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1]], device='cuda:0')}\n",
            "Logits: tensor([[ 1.4523, -2.7290,  3.7289,  2.1192, -6.1515, -1.8035]],\n",
            "       device='cuda:0')\n",
            "Predicted class: 2\n",
            "Predicted label: intent_negative\n",
            "Question: Không sao! Cậu có muốn thử lại không?\n",
            "Answer: Tớ không muốn chơi nữa.\n",
            "Inputs: {'input_ids': tensor([[  101,   101,  1047, 19991,  7509,   999,  6187,  2226,  2522, 14163,\n",
            "          2239, 16215,  2226, 21110,  1047, 19991,  1029,   102,  2000,  1047,\n",
            "         19991, 14163,  2239, 18151, 16371,  2050,  1012,   102,   102]],\n",
            "       device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1]], device='cuda:0')}\n",
            "Logits: tensor([[-0.4931, -2.5996,  3.8942, -1.2380, -3.2890, -0.7055]],\n",
            "       device='cuda:0')\n",
            "Predicted class: 2\n",
            "Predicted label: intent_negative\n",
            "Question: Cậu có thể cho tớ biết thêm từ nào không?\n",
            "Answer: Tớ chưa nghĩ ra.\n",
            "Inputs: {'input_ids': tensor([[  101,   101,  6187,  2226,  2522,  1996, 16480,  2000, 12170,  3388,\n",
            "          2068, 10722,  6583,  2080,  1047, 19991,  1029,   102,  2000, 14684,\n",
            "          2050, 12835,  4048, 10958,  1012,   102,   102]], device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1]], device='cuda:0')}\n",
            "Logits: tensor([[-1.8153, -1.2719, -3.7170,  4.4650,  0.1280, -0.2901]],\n",
            "       device='cuda:0')\n",
            "Predicted class: 3\n",
            "Predicted label: intent_neutral\n",
            "Question: Cậu có muốn thử một chủ đề khác không?\n",
            "Answer: Tớ không biết.\n",
            "Inputs: {'input_ids': tensor([[  101,   101,  6187,  2226,  2522, 14163,  2239, 16215,  2226,  9587,\n",
            "          2102, 14684,  1102,  2063,  1047,  3270,  2278,  1047, 19991,  1029,\n",
            "           102,  2000,  1047, 19991, 12170,  3388,  1012,   102,   102]],\n",
            "       device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1]], device='cuda:0')}\n",
            "Logits: tensor([[ 0.8102, -0.1721, -2.7499,  2.1816, -2.5223, -1.6377]],\n",
            "       device='cuda:0')\n",
            "Predicted class: 3\n",
            "Predicted label: intent_neutral\n",
            "Question: Cậu có muốn tìm hiểu thêm về các món ăn không?\n",
            "Answer: Có, tớ muốn biết thêm.\n",
            "Inputs: {'input_ids': tensor([[  101,   101,  6187,  2226,  2522, 14163,  2239,  5199,  7632, 13765,\n",
            "          2068,  2310,  6187,  2278, 12256,  2019,  1047, 19991,  1029,   102,\n",
            "          2522,  1010,  2000, 14163,  2239, 12170,  3388,  2068,  1012,   102,\n",
            "           102]], device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n",
            "Logits: tensor([[-3.1926,  8.9815, -4.2924, -1.1402, -2.4110, -2.0628]],\n",
            "       device='cuda:0')\n",
            "Predicted class: 1\n",
            "Predicted label: intent_learn_more\n",
            "Question: Tuyệt vời! Cậu muốn biết về món ăn nào?\n",
            "Answer: Tớ muốn biết về pizza.\n",
            "Inputs: {'input_ids': tensor([[  101,   101, 10722,  6672,  2102, 29536,  2072,   999,  6187,  2226,\n",
            "         14163,  2239, 12170,  3388,  2310, 12256,  2019,  6583,  2080,  1029,\n",
            "           102,  2000, 14163,  2239, 12170,  3388,  2310, 10733,  1012,   102,\n",
            "           102]], device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n",
            "Logits: tensor([[-3.5190,  4.7083, -3.5711, -2.1000,  1.1228, -1.3985]],\n",
            "       device='cuda:0')\n",
            "Predicted class: 1\n",
            "Predicted label: intent_learn_more\n",
            "Question: Cậu có biết ăn uống lành mạnh là gì không?\n",
            "Answer: Tớ không thích nói về điều đó.\n",
            "Inputs: {'input_ids': tensor([[  101,   101,  6187,  2226,  2522, 12170,  3388,  2019,  1057,  5063,\n",
            "         17595,  2232,  2158,  2232,  2474, 21025,  1047, 19991,  1029,   102,\n",
            "          2000,  1047, 19991, 16215,  7033,  2053,  2072,  2310,  1102, 17301,\n",
            "          1102,  2080,  1012,   102,   102]], device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n",
            "Logits: tensor([[ 2.1448,  0.1568, -2.3119,  0.2156, -1.2406, -2.8515]],\n",
            "       device='cuda:0')\n",
            "Predicted class: 0\n",
            "Predicted label: intent_fallback\n",
            "Question: Cậu có biết ăn uống lành mạnh là gì không?\n",
            "Answer: Tớ không muốn trả lời.\n",
            "Inputs: {'input_ids': tensor([[  101,   101,  6187,  2226,  2522, 12170,  3388,  2019,  1057,  5063,\n",
            "         17595,  2232,  2158,  2232,  2474, 21025,  1047, 19991,  1029,   102,\n",
            "          2000,  1047, 19991, 14163,  2239, 19817,  2050,  8840,  2072,  1012,\n",
            "           102,   102]], device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n",
            "Logits: tensor([[ 0.6727,  1.0282, -0.8731, -0.0590, -2.1456, -1.1401]],\n",
            "       device='cuda:0')\n",
            "Predicted class: 1\n",
            "Predicted label: intent_learn_more\n",
            "Question: Cậu có muốn tiếp tục không?\n",
            "Answer: \n",
            "Inputs: {'input_ids': tensor([[  101,   101,  6187,  2226,  2522, 14163,  2239,  5495,  2361, 10722,\n",
            "          2278,  1047, 19991,  1029,   102,   102,   102]], device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n",
            "Logits: tensor([[-3.6498, -0.9419, -4.4682, -0.1613, -0.3317,  4.5921]],\n",
            "       device='cuda:0')\n",
            "Predicted class: 5\n",
            "Predicted label: silence\n",
            "Question: Cậu có muốn chơi tiếp không?\n",
            "Answer: \n",
            "Inputs: {'input_ids': tensor([[  101,   101,  6187,  2226,  2522, 14163,  2239, 18151,  5495,  2361,\n",
            "          1047, 19991,  1029,   102,   102,   102]], device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n",
            "Logits: tensor([[-3.1710, -1.3924, -3.3627,  0.6944, -1.4327,  2.9253]],\n",
            "       device='cuda:0')\n",
            "Predicted class: 5\n",
            "Predicted label: silence\n",
            "Question: Được rồi, bây giờ chúng ta sẽ chơi một trò chơi! Hãy kể tên nhiều từ thuộc cùng 1 chủ đề nhé. Chủ đề lần này là hành động bắt đầu bằng từ \"Drink water\". Tớ ví dụ nhé, \"drink water\", đến lượt cậu nhé!\n",
            "Answer: Tớ có thể nói \"drink juice\".\n",
            "Inputs: {'input_ids': tensor([[  101,   101,  1102, 19098,  2278, 25223,  1010,  3016, 21025,  2080,\n",
            "         15972, 11937,  7367, 18151,  9587,  2102, 19817,  2080, 18151,   999,\n",
            "         10974, 17710,  2702, 18699, 17301, 10722, 16215, 19098,  2278, 12731,\n",
            "          3070,  1015, 14684,  1102,  2063, 18699,  2063,  1012, 14684,  1102,\n",
            "          2063, 17595, 29349,  2474,  7658,  2232,  1102,  5063,  7151,  1102,\n",
            "          4887,  9748, 10722,  1000,  4392,  2300,  1000,  1012,  2000,  6819,\n",
            "          4241, 18699,  2063,  1010,  1000,  4392,  2300,  1000,  1010,  1102,\n",
            "          2368, 11320,  4140,  6187,  2226, 18699,  2063,   999,   102,  2000,\n",
            "          2522,  1996,  2053,  2072,  1000,  4392, 10869,  1000,  1012,   102,\n",
            "           102]], device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0')}\n",
            "Logits: tensor([[-2.9337, -0.7582, -2.9137, -0.8271,  6.4527, -4.1159]],\n",
            "       device='cuda:0')\n",
            "Predicted class: 4\n",
            "Predicted label: intent_positive\n",
            "Question: Tốt lắm! Cậu có từ nào khác không?\n",
            "Answer: Tớ không biết nữa.\n",
            "Inputs: {'input_ids': tensor([[  101,   101,  2000,  2102, 16983,   999,  6187,  2226,  2522, 10722,\n",
            "          6583,  2080,  1047,  3270,  2278,  1047, 19991,  1029,   102,  2000,\n",
            "          1047, 19991, 12170,  3388, 16371,  2050,  1012,   102,   102]],\n",
            "       device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1]], device='cuda:0')}\n",
            "Logits: tensor([[-0.9054, -3.9451,  3.2511,  1.4114, -2.6756, -1.0447]],\n",
            "       device='cuda:0')\n",
            "Predicted class: 2\n",
            "Predicted label: intent_negative\n",
            "Question: Không sao, cậu có thể nghĩ thêm không? Chủ đề là \"Drink water\".\n",
            "Answer: Tớ chưa nghĩ ra từ nào khác.\n",
            "Inputs: {'input_ids': tensor([[  101,   101,  1047, 19991,  7509,  1010,  6187,  2226,  2522,  1996,\n",
            "         12835,  4048,  2068,  1047, 19991,  1029, 14684,  1102,  2063,  2474,\n",
            "          1000,  4392,  2300,  1000,  1012,   102,  2000, 14684,  2050, 12835,\n",
            "          4048, 10958, 10722,  6583,  2080,  1047,  3270,  2278,  1012,   102,\n",
            "           102]], device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n",
            "Logits: tensor([[-1.5936, -2.7042, -1.9352,  4.9620, -0.2123, -1.4123]],\n",
            "       device='cuda:0')\n",
            "Predicted class: 3\n",
            "Predicted label: intent_neutral\n",
            "Question: Cậu có thể thử nghĩ thêm một số từ khác không? Ví dụ như \"drink soda\".\n",
            "Answer: Tớ muốn tìm hiểu thêm về các loại đồ uống.\n",
            "Inputs: {'input_ids': tensor([[  101,   101,  6187,  2226,  2522,  1996, 16215,  2226, 12835,  4048,\n",
            "          2068,  9587,  2102,  2061, 10722,  1047,  3270,  2278,  1047, 19991,\n",
            "          1029,  6819,  4241, 18699,  2226,  1000,  4392, 14904,  1000,  1012,\n",
            "           102,  2000, 14163,  2239,  5199,  7632, 13765,  2068,  2310,  6187,\n",
            "          2278,  8840,  4886,  1102,  2080,  1057,  5063,  1012,   102,   102]],\n",
            "       device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1]], device='cuda:0')}\n",
            "Logits: tensor([[-2.5523,  6.1298, -4.4242, -0.5033, -0.3047, -2.1138]],\n",
            "       device='cuda:0')\n",
            "Predicted class: 1\n",
            "Predicted label: intent_learn_more\n",
            "Question: Cậu có biết từ nào khác không? Hãy thử nhé!\n",
            "Answer: Tớ không thích trò chơi này.\n",
            "Inputs: {'input_ids': tensor([[  101,   101,  6187,  2226,  2522, 12170,  3388, 10722,  6583,  2080,\n",
            "          1047,  3270,  2278,  1047, 19991,  1029, 10974, 16215,  2226, 18699,\n",
            "          2063,   999,   102,  2000,  1047, 19991, 16215,  7033, 19817,  2080,\n",
            "         18151, 29349,  1012,   102,   102]], device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n",
            "Logits: tensor([[ 1.9964, -4.1743,  1.0657, -0.9429, -0.7058, -1.5697]],\n",
            "       device='cuda:0')\n",
            "Predicted class: 0\n",
            "Predicted label: intent_fallback\n",
            "Question: Cậu có thể nói một từ khác không? Hãy thử nhé!\n",
            "Answer: \n",
            "Inputs: {'input_ids': tensor([[  101,   101,  6187,  2226,  2522,  1996,  2053,  2072,  9587,  2102,\n",
            "         10722,  1047,  3270,  2278,  1047, 19991,  1029, 10974, 16215,  2226,\n",
            "         18699,  2063,   999,   102,   102,   102]], device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1]], device='cuda:0')}\n",
            "Logits: tensor([[-3.1775, -2.2955, -5.3162, -1.3340,  0.0640,  6.4354]],\n",
            "       device='cuda:0')\n",
            "Predicted class: 5\n",
            "Predicted label: silence\n",
            "Question: Cậu có thể kể tên một số đồ uống không? Ví dụ như \"drink tea\".\n",
            "Answer: Tớ biết \"drink milk\".\n",
            "Inputs: {'input_ids': tensor([[  101,   101,  6187,  2226,  2522,  1996, 17710,  2702,  9587,  2102,\n",
            "          2061,  1102,  2080,  1057,  5063,  1047, 19991,  1029,  6819,  4241,\n",
            "         18699,  2226,  1000,  4392,  5572,  1000,  1012,   102,  2000, 12170,\n",
            "          3388,  1000,  4392,  6501,  1000,  1012,   102,   102]],\n",
            "       device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n",
            "Logits: tensor([[-1.8255,  0.5745, -4.6359,  0.3191,  4.4381, -1.9391]],\n",
            "       device='cuda:0')\n",
            "Predicted class: 4\n",
            "Predicted label: intent_positive\n",
            "Question: Rất tốt! Cậu có từ nào khác không?\n",
            "Answer: Tớ không biết thêm từ nào nữa.\n",
            "Inputs: {'input_ids': tensor([[  101,   101,  9350,  2000,  2102,   999,  6187,  2226,  2522, 10722,\n",
            "          6583,  2080,  1047,  3270,  2278,  1047, 19991,  1029,   102,  2000,\n",
            "          1047, 19991, 12170,  3388,  2068, 10722,  6583,  2080, 16371,  2050,\n",
            "          1012,   102,   102]], device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n",
            "Logits: tensor([[-0.7826, -2.3723,  3.2218,  1.1636, -2.7911, -2.0103]],\n",
            "       device='cuda:0')\n",
            "Predicted class: 2\n",
            "Predicted label: intent_negative\n",
            "Question: Cậu có thể nghĩ thêm không? Chủ đề là \"Drink water\".\n",
            "Answer: Tớ không chắc lắm.\n",
            "Inputs: {'input_ids': tensor([[  101,   101,  6187,  2226,  2522,  1996, 12835,  4048,  2068,  1047,\n",
            "         19991,  1029, 14684,  1102,  2063,  2474,  1000,  4392,  2300,  1000,\n",
            "          1012,   102,  2000,  1047, 19991, 15775,  2278, 16983,  1012,   102,\n",
            "           102]], device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n",
            "Logits: tensor([[-2.4498, -1.8845, -1.8657,  4.6280, -0.1745, -2.4011]],\n",
            "       device='cuda:0')\n",
            "Predicted class: 3\n",
            "Predicted label: intent_neutral\n",
            "Question: Cậu có thể thử nghĩ thêm một số từ khác không? Ví dụ như \"drink lemonade\".\n",
            "Answer: Tớ muốn biết thêm về các loại nước uống.\n",
            "Inputs: {'input_ids': tensor([[  101,   101,  6187,  2226,  2522,  1996, 16215,  2226, 12835,  4048,\n",
            "          2068,  9587,  2102,  2061, 10722,  1047,  3270,  2278,  1047, 19991,\n",
            "          1029,  6819,  4241, 18699,  2226,  1000,  4392, 14380,  9648,  1000,\n",
            "          1012,   102,  2000, 14163,  2239, 12170,  3388,  2068,  2310,  6187,\n",
            "          2278,  8840,  4886, 16371, 10085,  1057,  5063,  1012,   102,   102]],\n",
            "       device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1]], device='cuda:0')}\n",
            "Logits: tensor([[-1.0277,  6.3187, -4.0147, -0.8607, -1.5971, -1.9456]],\n",
            "       device='cuda:0')\n",
            "Predicted class: 1\n",
            "Predicted label: intent_learn_more\n",
            "Question: Cậu có biết từ nào khác không? Hãy thử nhé!\n",
            "Answer: Tớ không muốn chơi nữa.\n",
            "Inputs: {'input_ids': tensor([[  101,   101,  6187,  2226,  2522, 12170,  3388, 10722,  6583,  2080,\n",
            "          1047,  3270,  2278,  1047, 19991,  1029, 10974, 16215,  2226, 18699,\n",
            "          2063,   999,   102,  2000,  1047, 19991, 14163,  2239, 18151, 16371,\n",
            "          2050,  1012,   102,   102]], device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n",
            "Logits: tensor([[ 1.1245, -2.7674,  2.1871, -0.5472, -4.1364,  0.3947]],\n",
            "       device='cuda:0')\n",
            "Predicted class: 2\n",
            "Predicted label: intent_negative\n",
            "Question: Cậu có thể kể tên một số đồ uống không? Ví dụ như \"drink coffee\".\n",
            "Answer: \n",
            "Inputs: {'input_ids': tensor([[  101,   101,  6187,  2226,  2522,  1996, 17710,  2702,  9587,  2102,\n",
            "          2061,  1102,  2080,  1057,  5063,  1047, 19991,  1029,  6819,  4241,\n",
            "         18699,  2226,  1000,  4392,  4157,  1000,  1012,   102,   102,   102]],\n",
            "       device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1]], device='cuda:0')}\n",
            "Logits: tensor([[-2.6299,  0.4011, -5.2731, -0.1899,  3.5264,  0.4574]],\n",
            "       device='cuda:0')\n",
            "Predicted class: 4\n",
            "Predicted label: intent_positive\n",
            "Question: Được rồi, bây giờ chúng ta sẽ chơi một trò chơi! Hãy kể tên nhiều từ thuộc cùng 1 chủ đề nhé. Chủ đề lần này là hành động bắt đầu bằng từ 'play'. Tớ ví dụ nhé, 'play football', đến lượt cậu nhé!\n",
            "Answer: Tớ có thể nói 'play basketball'.\n",
            "Inputs: {'input_ids': tensor([[  101,   101,  1102, 19098,  2278, 25223,  1010,  3016, 21025,  2080,\n",
            "         15972, 11937,  7367, 18151,  9587,  2102, 19817,  2080, 18151,   999,\n",
            "         10974, 17710,  2702, 18699, 17301, 10722, 16215, 19098,  2278, 12731,\n",
            "          3070,  1015, 14684,  1102,  2063, 18699,  2063,  1012, 14684,  1102,\n",
            "          2063, 17595, 29349,  2474,  7658,  2232,  1102,  5063,  7151,  1102,\n",
            "          4887,  9748, 10722,  1005,  2377,  1005,  1012,  2000,  6819,  4241,\n",
            "         18699,  2063,  1010,  1005,  2377,  2374,  1005,  1010,  1102,  2368,\n",
            "         11320,  4140,  6187,  2226, 18699,  2063,   999,   102,  2000,  2522,\n",
            "          1996,  2053,  2072,  1005,  2377,  3455,  1005,  1012,   102,   102]],\n",
            "       device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0')}\n",
            "Logits: tensor([[-3.3514,  0.3694, -2.9614, -1.3313,  6.9685, -4.7272]],\n",
            "       device='cuda:0')\n",
            "Predicted class: 4\n",
            "Predicted label: intent_positive\n",
            "Question: Tuyệt vời! Cậu đã có 1 điểm. Còn từ nào khác không?\n",
            "Answer: Tớ không biết nữa.\n",
            "Inputs: {'input_ids': tensor([[  101,   101, 10722,  6672,  2102, 29536,  2072,   999,  6187,  2226,\n",
            "          1102,  2050,  2522,  1015,  1102,  2666,  2213,  1012,  9530, 10722,\n",
            "          6583,  2080,  1047,  3270,  2278,  1047, 19991,  1029,   102,  2000,\n",
            "          1047, 19991, 12170,  3388, 16371,  2050,  1012,   102,   102]],\n",
            "       device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n",
            "Logits: tensor([[-1.7108, -2.9616,  2.8492,  0.8826, -1.6318, -2.1049]],\n",
            "       device='cuda:0')\n",
            "Predicted class: 2\n",
            "Predicted label: intent_negative\n",
            "Question: Không sao, cậu có thể nghĩ thêm nhé! Tớ đã có 1 điểm, cậu có muốn thử không?\n",
            "Answer: Tớ cũng không chắc lắm.\n",
            "Inputs: {'input_ids': tensor([[  101,   101,  1047, 19991,  7509,  1010,  6187,  2226,  2522,  1996,\n",
            "         12835,  4048,  2068, 18699,  2063,   999,  2000,  1102,  2050,  2522,\n",
            "          1015,  1102,  2666,  2213,  1010,  6187,  2226,  2522, 14163,  2239,\n",
            "         16215,  2226,  1047, 19991,  1029,   102,  2000, 12731,  3070,  1047,\n",
            "         19991, 15775,  2278, 16983,  1012,   102,   102]], device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0')}\n",
            "Logits: tensor([[-2.3727, -0.3937, -1.1977,  5.2413, -3.5167, -1.8026]],\n",
            "       device='cuda:0')\n",
            "Predicted class: 3\n",
            "Predicted label: intent_neutral\n",
            "Question: Cậu có thể hỏi tớ nếu cần giúp đỡ! Còn từ nào khác không?\n",
            "Answer: Tớ muốn biết thêm về các từ khác.\n",
            "Inputs: {'input_ids': tensor([[  101,   101,  6187,  2226,  2522,  1996,  7570,  2072,  2000, 11265,\n",
            "          2226,  2064, 21025,  6279,  1102,  2080,   999,  9530, 10722,  6583,\n",
            "          2080,  1047,  3270,  2278,  1047, 19991,  1029,   102,  2000, 14163,\n",
            "          2239, 12170,  3388,  2068,  2310,  6187,  2278, 10722,  1047,  3270,\n",
            "          2278,  1012,   102,   102]], device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
            "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
            "       device='cuda:0')}\n",
            "Logits: tensor([[-2.0565,  6.9095, -4.4992, -0.9136, -1.6670, -0.6853]],\n",
            "       device='cuda:0')\n",
            "Predicted class: 1\n",
            "Predicted label: intent_learn_more\n",
            "Question: Chúng ta có thể nói về nhiều từ khác nhau! Cậu có biết 'play chess' không?\n",
            "Answer: Tớ không thích chơi cờ.\n",
            "Inputs: {'input_ids': tensor([[  101,   101, 15972, 11937,  2522,  1996,  2053,  2072,  2310, 18699,\n",
            "         17301, 10722,  1047,  3270,  2278, 18699,  4887,   999,  6187,  2226,\n",
            "          2522, 12170,  3388,  1005,  2377,  7433,  1005,  1047, 19991,  1029,\n",
            "           102,  2000,  1047, 19991, 16215,  7033, 18151,  2522,  1012,   102,\n",
            "           102]], device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n",
            "Logits: tensor([[ 1.0113, -2.5985,  0.8253, -1.2028, -0.3971, -2.7360]],\n",
            "       device='cuda:0')\n",
            "Predicted class: 0\n",
            "Predicted label: intent_fallback\n",
            "Question: Không sao, mỗi người có sở thích khác nhau mà! Cậu có biết 'play video games' không?\n",
            "Answer: \n",
            "Inputs: {'input_ids': tensor([[  101,   101,  1047, 19991,  7509,  1010, 25175, 12835, 19098,  2072,\n",
            "          2522,  2061, 16215,  7033,  1047,  3270,  2278, 18699,  4887,  5003,\n",
            "           999,  6187,  2226,  2522, 12170,  3388,  1005,  2377,  2678,  2399,\n",
            "          1005,  1047, 19991,  1029,   102,   102,   102]], device='cuda:0'), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}\n",
            "Logits: tensor([[-1.5910, -1.1745, -3.8656, -0.9971,  1.9989,  0.2840]],\n",
            "       device='cuda:0')\n",
            "Predicted class: 4\n",
            "Predicted label: intent_positive\n",
            "Accuracy: 83.33%\n",
            "Evaluation results saved to evaluation_results.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O7cItUfQxhG5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
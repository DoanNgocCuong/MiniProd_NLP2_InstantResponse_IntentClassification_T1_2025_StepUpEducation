{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"4fdd4314ed9245a3b31e0740f39126d3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8a4b342e7df34eb8a7c4e710960d296d","IPY_MODEL_ad1333081bc346ec8339f7f3e5a84937","IPY_MODEL_286ad81dd3c24185af539bdb5c8d8e23"],"layout":"IPY_MODEL_58b298160fc54371a37c478d75e20ab6"}},"8a4b342e7df34eb8a7c4e710960d296d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a53441adcc23464f8c366bcc89f38941","placeholder":"​","style":"IPY_MODEL_48557156879a4a0594133d8e0c466b46","value":"Map: 100%"}},"ad1333081bc346ec8339f7f3e5a84937":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ffabed4a2222402697e7a491ea763bdd","max":3000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_68d40b5a232248bf8841c3fc6784a880","value":3000}},"286ad81dd3c24185af539bdb5c8d8e23":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4ac0d45ca2d544e3913a0e406c41ab72","placeholder":"​","style":"IPY_MODEL_097126d716eb4a40a7de3e81b081eca7","value":" 3000/3000 [00:00&lt;00:00, 3896.11 examples/s]"}},"58b298160fc54371a37c478d75e20ab6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a53441adcc23464f8c366bcc89f38941":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48557156879a4a0594133d8e0c466b46":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ffabed4a2222402697e7a491ea763bdd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"68d40b5a232248bf8841c3fc6784a880":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4ac0d45ca2d544e3913a0e406c41ab72":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"097126d716eb4a40a7de3e81b081eca7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"acf7c77292794fad920b64b7071fdb4b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e3eae18482894bac9eb3674a218b870e","IPY_MODEL_70e23f0c48ed43beacf7ec7f355cd56e","IPY_MODEL_af317354b9294f44bb6f6f658a50679b"],"layout":"IPY_MODEL_a4cc6bff36904dbabd1854d31b89585d"}},"e3eae18482894bac9eb3674a218b870e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_75c7d6db01cd4bb787457bb62249b44b","placeholder":"​","style":"IPY_MODEL_7de88586f7c14512b4c0737faf918195","value":"model.safetensors: 100%"}},"70e23f0c48ed43beacf7ec7f355cd56e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_28976e6176ab463d9a0d81ebcddf821f","max":267954768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b30be8a2f62547968c23ef8a9c68f79c","value":267954768}},"af317354b9294f44bb6f6f658a50679b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7909655735747948742609f58d40880","placeholder":"​","style":"IPY_MODEL_7c615506e3854c1bb7775927b294ebdc","value":" 268M/268M [00:02&lt;00:00, 114MB/s]"}},"a4cc6bff36904dbabd1854d31b89585d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75c7d6db01cd4bb787457bb62249b44b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7de88586f7c14512b4c0737faf918195":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"28976e6176ab463d9a0d81ebcddf821f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b30be8a2f62547968c23ef8a9c68f79c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b7909655735747948742609f58d40880":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c615506e3854c1bb7775927b294ebdc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10401900,"sourceType":"datasetVersion","datasetId":6445361}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"5d70924a","cell_type":"markdown","source":"# Import necessary libraries","metadata":{"id":"5d70924a"}},{"id":"ce7f892c-a92d-4faa-976e-beae20abaaa4","cell_type":"code","source":"from transformers import AutoTokenizer, TrainingArguments, Trainer, AutoModel\nimport numpy as np\nimport torch\nfrom datasets import load_dataset\nimport torch.nn as nn\nimport os\nfrom typing import List\nfrom tqdm import tqdm\n\n\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" ## Setup CUDA GPU 1\n\n\nclass BERTIntentClassification(nn.Module):\n    \n    \n    def __init__(self, model_name=\"bert-base-uncased\", num_classes=10, dropout_rate=0.1, cache_dir = \"huggingface\"):\n        super(BERTIntentClassification, self).__init__()\n        self.bert = AutoModel.from_pretrained(model_name, cache_dir = cache_dir)\n        # Get BERT hidden size\n        hidden_size = self.bert.config.hidden_size\n        self.ffnn = nn.Sequential(\n            nn.Linear(hidden_size, hidden_size),\n            nn.LayerNorm(hidden_size),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate),\n            nn.Linear(hidden_size, num_classes)\n        )\n\n    \n    def freeze_bert(self):\n        for param in self.bert.parameters():\n            param.requires_grad = False\n\n\n    def get_pooling(self, hidden_state, attention_mask):\n        \"\"\"\n        Get mean pooled representation from BERT hidden states\n        Args:\n            hidden_state: BERT output containing hidden states\n        Returns:\n            pooled_output: Mean pooled representation of the sequence\n        \"\"\"\n        # Get last hidden state\n        last_hidden_state = hidden_state.last_hidden_state  # Shape: [batch_size, seq_len, hidden_size]\n        \n        if attention_mask is not None:\n            # Expand attention mask to match hidden state dimensions\n            attention_mask = attention_mask.unsqueeze(-1)  # [batch_size, seq_len, 1]\n            \n            # Mask out padding tokens\n            masked_hidden = last_hidden_state * attention_mask\n            \n            # Calculate mean (sum / number of actual tokens)\n            sum_hidden = torch.sum(masked_hidden, dim=1)  # [batch_size, hidden_size]\n            count_tokens = torch.sum(attention_mask, dim=1)  # [batch_size, 1]\n            pooled_output = sum_hidden / count_tokens\n        else:\n            # If no attention mask, simply take mean of all tokens\n            pooled_output = torch.mean(last_hidden_state, dim=1)\n        \n        return pooled_output\n        \n    \n    def forward(self, input_ids, attention_mask, **kwargs):\n        \"\"\"\n        Forward pass of the model\n        Args:\n            input_ids: Input token IDs\n            attention_mask: Attention mask for padding\n        Returns:\n            logits: Raw logits for each class\n        \"\"\"\n        # Get BERT hidden states\n        hidden_state = self.bert(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n        )\n        \n        # Get pooled representation\n        hidden_state_pooling = self.get_pooling(hidden_state=hidden_state, attention_mask=attention_mask)\n        \n        # Pass through FFNN classifier\n        logits = self.ffnn(hidden_state_pooling)\n        \n        return logits\n\n\n\nclass TrainerCustom(Trainer):\n\n    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n        \"\"\"\n        How the loss is computed by Trainer. By default, all models return the loss in the first element.\n\n        Subclass and override for custom behavior.\n        \"\"\"\n        if \"labels\" in inputs:\n            labels = inputs.pop(\"labels\")\n        else:\n            labels = None\n        \n        # Sử dụng nn.CrossEntropyLoss() thay vì nn.CrossEntropy\n        cross_entropy_loss = nn.CrossEntropyLoss()\n        \n        # Chạy mô hình và nhận đầu ra (logits)\n        outputs = model(**inputs)\n        \n        # Đảm bảo lấy logits từ outputs (mô hình trả về tuple, lấy phần tử đầu tiên là logits)\n        logits = outputs\n        \n        # Tính toán loss\n        loss = cross_entropy_loss(logits, labels)\n        \n        # Trả về loss và outputs nếu cần\n        return (loss, outputs) if return_outputs else loss\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T09:25:40.460362Z","iopub.execute_input":"2025-01-08T09:25:40.460630Z"}},"outputs":[],"execution_count":null},{"id":"Dmhw2Y7E9cfm","cell_type":"code","source":"\n\n# Bước 1: Tải dữ liệu\n# Sử dụng dataset sẵn có từ Hugging Face hoặc tải từ file cục bộ\ndataset = load_dataset(\"imdb\", cache_dir = \"huggingface\")  # Ví dụ: Dữ liệu IMDB để phân loại sentiment\n# Thay thế trường 'text' thành 'input_ids' trong train_dataset và test_dataset\ndef preprocess_dataset(dataset):\n    return dataset.map(lambda example: {\n            \"input_ids\": example['text'],\n            \"label\": example['label']\n        }, \n        remove_columns=[\"text\"],\n        num_proc=4  # Sử dụng 4 tiến trình song song để xử lý nhanh hơn\n    )\n\ntrain_dataset = preprocess_dataset(dataset[\"train\"])\ntest_dataset = preprocess_dataset(dataset[\"test\"])","metadata":{"id":"Dmhw2Y7E9cfm","trusted":true},"outputs":[],"execution_count":null},{"id":"aca95911-c069-4860-8bea-fe3c97b9415d","cell_type":"code","source":"\n# Bước 2: Chuẩn bị tokenizer và token hóa dữ liệu\nmodel_name = \"bert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir = \"huggingface\")\nmodel = BERTIntentClassification(\n    model_name=model_name,\n    num_classes=2\n)\nmodel.freeze_bert() # Froze Layer BERT\nmax_seq_length = 512\n\n\ndef collate_fn(features):\n    inputs = []\n    labels = []\n    for element in features:\n        inputs.append(element.get(\"input_ids\"))\n        labels.append(element.get(\"label\"))\n    \n    labels = torch.tensor(labels, dtype=torch.long)\n    \n    token_inputs = tokenizer(\n        inputs,\n        add_special_tokens=True,\n        truncation=True,\n        padding=True,\n        max_length=max_seq_length,\n        return_overflowing_tokens=False,\n        return_length=False,\n        return_tensors=\"pt\",\n    )\n    token_inputs.update({\n        \"labels\": labels,\n    })\n    return token_inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T09:15:59.490691Z","iopub.execute_input":"2025-01-08T09:15:59.490974Z","iopub.status.idle":"2025-01-08T09:16:04.213529Z","shell.execute_reply.started":"2025-01-08T09:15:59.490949Z","shell.execute_reply":"2025-01-08T09:16:04.212614Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1712a2989304f7ba753ebe1efe6ca7c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"599872d0af2a44bd983f292fc9a77380"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fe282cbb2454f3f963670ebe399076c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a86ddc1f7814ac1b55de626975e4693"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a22dd90f2f4d492ebfc9bbe011063518"}},"metadata":{}}],"execution_count":3},{"id":"974f4108-44cb-4962-8219-9434de648d45","cell_type":"code","source":"\n\n\n# training_args = TrainingArguments(\n#     output_dir=\"./results\",          # Thư mục lưu kết quả\n#     eval_strategy=\"epoch\",    # Đánh giá sau mỗi epoch\n#     learning_rate=2e-4,\n#     per_device_train_batch_size=128,\n#     per_device_eval_batch_size=128,\n#     num_train_epochs=50,\n#     weight_decay=0.01,\n#     logging_dir=\"./logs\",\n#     logging_steps=None,\n#     logging_strategy = \"epoch\",\n#     save_strategy=\"epoch\",          # Lưu trọng số sau mỗi epoch\n#     save_total_limit=3,\n# )\n\n# Bước 6: Cài đặt tham số huấn luyện\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    evaluation_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    save_strategy=\"epoch\",\n    logging_dir=\"./logs\",\n    logging_steps=10,  # Ghi log sau mỗi 10 bước\n    logging_strategy=\"steps\"  # Đảm bảo ghi log theo steps\n)\n\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-08T09:25:14.176Z"}},"outputs":[],"execution_count":null},{"id":"68f917a7-48fa-4934-bb33-3c2c91e2f243","cell_type":"code","source":"\n# Bước 7: Tạo Trainer\ntrainer = TrainerCustom(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=test_dataset,\n    tokenizer=tokenizer,\n    data_collator = collate_fn,\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T09:16:30.507958Z","iopub.execute_input":"2025-01-08T09:16:30.508308Z","iopub.status.idle":"2025-01-08T09:16:32.474264Z","shell.execute_reply.started":"2025-01-08T09:16:30.508282Z","shell.execute_reply":"2025-01-08T09:16:32.473227Z"}},"outputs":[],"execution_count":5},{"id":"923746ca-63f8-42b6-9bc3-d6677872bd47","cell_type":"code","source":"\n# Bước 8: Huấn luyện\ntrainer.train()\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"fde7a9a2-91ac-4218-9ce4-63a23a76cdec","cell_type":"code","source":"# Bước 9: Đánh giá trên tập kiểm tra\ntrainer.evaluate()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
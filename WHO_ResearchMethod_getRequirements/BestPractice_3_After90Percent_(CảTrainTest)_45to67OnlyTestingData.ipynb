{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong lƒ©nh v·ª±c ph√¢n lo·∫°i √Ω ƒë·ªãnh (intent classification), c√°c m√¥ h√¨nh ti√™n ti·∫øn nh·∫•t hi·ªán nay bao g·ªìm:\n",
    "\n",
    "- **mT5 Base (encoder-only)**: ƒê·∫°t ƒë∆∞·ª£c ƒë·ªô ch√≠nh x√°c 86,1% tr√™n b·ªô d·ªØ li·ªáu MASSIVE, ƒë√¢y l√† m·ªôt trong nh·ªØng m√¥ h√¨nh h√†ng ƒë·∫ßu cho nhi·ªám v·ª• n√†y. \n",
    "\n",
    "- **XLM-Roberta**: ƒê∆∞·ª£c s·ª≠ d·ª•ng r·ªông r√£i trong c√°c d·ª± √°n ph√¢n lo·∫°i √Ω ƒë·ªãnh, XLM-Roberta cung c·∫•p hi·ªáu su·∫•t cao v√† kh·∫£ nƒÉng √°p d·ª•ng ƒëa ng√¥n ng·ªØ. \n",
    "\n",
    "- **Joint BERT**: M√¥ h√¨nh k·∫øt h·ª£p BERT cho c·∫£ ph√¢n lo·∫°i √Ω ƒë·ªãnh v√† ƒëi·ªÅn khe (slot filling), ƒë·∫°t ƒë·ªô ch√≠nh x√°c cao tr√™n c√°c b·ªô d·ªØ li·ªáu nh∆∞ Snips v√† ATIS. \n",
    "\n",
    "- **ILLUMINER**: S·ª≠ d·ª•ng c√°c m√¥ h√¨nh ng√¥n ng·ªØ l·ªõn ƒë∆∞·ª£c tinh ch·ªânh theo h∆∞·ªõng d·∫´n (instruction-tuned), ILLUMINER cho th·∫•y hi·ªáu su·∫•t v∆∞·ª£t tr·ªôi trong vi·ªác ph√¢n lo·∫°i √Ω ƒë·ªãnh v√† ƒëi·ªÅn khe v·ªõi s·ªë l∆∞·ª£ng d·ªØ li·ªáu hu·∫•n luy·ªán h·∫°n ch·∫ø. \n",
    "\n",
    "- **Bi-directional Joint Neural Networks**: M√¥ h√¨nh n√†y s·ª≠ d·ª•ng c∆° ch·∫ø h·ªçc hai chi·ªÅu ƒë·ªÉ c·∫£i thi·ªán hi·ªáu su·∫•t trong c·∫£ ph√¢n lo·∫°i √Ω ƒë·ªãnh v√† ƒëi·ªÅn khe, ƒë·∫°t k·∫øt qu·∫£ xu·∫•t s·∫Øc tr√™n c√°c b·ªô d·ªØ li·ªáu chu·∫©n. \n",
    "\n",
    "Vi·ªác l·ª±a ch·ªçn m√¥ h√¨nh ph√π h·ª£p ph·ª• thu·ªôc v√†o y√™u c·∫ßu c·ª• th·ªÉ c·ªßa b√†i to√°n, bao g·ªìm ng√¥n ng·ªØ, k√≠ch th∆∞·ªõc d·ªØ li·ªáu v√† t√†i nguy√™n t√≠nh to√°n s·∫µn c√≥. \n",
    "\n",
    "---\n",
    "D∆∞·ªõi ƒë√¢y l√† c√°c li√™n k·∫øt ƒë·∫øn c√°c m√¥ h√¨nh ti√™n ti·∫øn nh·∫•t (SOTA) trong lƒ©nh v·ª±c **Intent Classification** m√† t√¥i ƒë√£ ƒë·ªÅ c·∫≠p:\n",
    "\n",
    "1. **mT5 Base (encoder-only)**:\n",
    "   - Link: [Papers with Code - Intent Classification on MASSIVE](https://paperswithcode.com/sota/intent-classification-on-massive)\n",
    "\n",
    "2. **XLM-Roberta**:\n",
    "   - Link: [GitHub Repository - Intent Detection using XLM-Roberta](https://github.com/MLArtist/intent-detection-using-XLM-Roberta)\n",
    "\n",
    "3. **Joint BERT**:\n",
    "   - Link: [Paper - Joint BERT for Intent Classification and Slot Filling](https://ar5iv.labs.arxiv.org/html/1902.10909)\n",
    "\n",
    "4. **ILLUMINER**:\n",
    "   - Link: [Arxiv Paper - Instruction-Tuned LLMs for Intent Detection](https://arxiv.org/abs/2403.17536)\n",
    "\n",
    "5. **Bi-directional Joint Neural Networks**:\n",
    "   - Link: [Arxiv Paper - Bi-directional Joint Neural Networks](https://arxiv.org/abs/2202.13079)\n",
    "\n",
    "N·∫øu c·∫ßn th√™m th√¥ng tin ho·∫∑c t√†i li·ªáu c·ª• th·ªÉ v·ªÅ b·∫•t k·ª≥ m√¥ h√¨nh n√†o, h√£y cho t√¥i bi·∫øt nh√©! üòä"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So s√°nh ƒë·ªÉ t√¨m ra BEST METHOD, ph√π h·ª£p v·ªõi data c·ªßa t√¥i \n",
    "\n",
    "```\n",
    "\n",
    "**C√°ch k·∫øt h·ª£p question v√† answer:**\n",
    "\n",
    "1. **Gh√©p n·ªëi tr·ª±c ti·∫øp:** B·∫°n c√≥ th·ªÉ k·∫øt h·ª£p c√¢u h·ªèi v√† c√¢u tr·∫£ l·ªùi th√†nh m·ªôt chu·ªói duy nh·∫•t, s·ª≠ d·ª•ng m·ªôt k√Ω t·ª± ƒë·∫∑c bi·ªát ho·∫∑c d·∫•u ph√¢n c√°ch ƒë·ªÉ t√°ch bi·ªát ch√∫ng. V√≠ d·ª•:\n",
    "\n",
    "   ```python\n",
    "   combined_text = question + \" [SEP] \" + answer\n",
    "   ```\n",
    "\n",
    "   Trong ƒë√≥, `[SEP]` l√† m·ªôt token ƒë·∫∑c bi·ªát th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng trong c√°c m√¥ h√¨nh nh∆∞ BERT ƒë·ªÉ ph√¢n t√°ch c√°c ƒëo·∫°n vƒÉn b·∫£n kh√°c nhau.\n",
    "\n",
    "2. **S·ª≠ d·ª•ng token ƒë·∫∑c bi·ªát:** M·ªôt s·ªë m√¥ h√¨nh h·ªó tr·ª£ c√°c token ƒë·∫∑c bi·ªát ƒë·ªÉ ƒë√°nh d·∫•u b·∫Øt ƒë·∫ßu v√† k·∫øt th√∫c c·ªßa c√¢u h·ªèi v√† c√¢u tr·∫£ l·ªùi. V√≠ d·ª•:\n",
    "\n",
    "   ```python\n",
    "   combined_text = \"[CLS] \" + question + \" [SEP] \" + answer + \" [SEP]\"\n",
    "   ```\n",
    "\n",
    "   - `[CLS]`: Token ƒë√°nh d·∫•u b·∫Øt ƒë·∫ßu chu·ªói (th∆∞·ªùng d√πng trong BERT).\n",
    "   - `[SEP]`: Token ph√¢n t√°ch gi·ªØa c√°c ph·∫ßn c·ªßa chu·ªói.\n",
    "\n",
    "```\n",
    "\n",
    "V√≠ d·ª• th·ª±c t·∫ø v·ªÅ chu·ªói chu·∫©n:\n",
    "\n",
    "M·ªôt c√¢u/ƒëo·∫°n duy nh·∫•t:\n",
    "```\n",
    "[CLS] This is the first sentence. [SEP]\n",
    "```\n",
    "Hai c√¢u/ƒëo·∫°n (v√≠ d·ª•: c√¢u h·ªèi v√† tr·∫£ l·ªùi):\n",
    "```\n",
    "[CLS] What is your name? [SEP] My name is John. [SEP]\n",
    "```\n",
    "Nhi·ªÅu c√¢u/ƒëo·∫°n (3 ƒëo·∫°n):\n",
    "```\n",
    "[CLS] Question 1 [SEP] Answer 1 [SEP] Extra information [SEP]\n",
    "```\n",
    "\n",
    "===\n",
    "\n",
    "Ti·∫øng anh v√† ti·∫øng vi·ªát. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```\n",
    "robot\tuser_answer\tuser_intent\n",
    "C·∫≠u c√≥ bi·∫øt c·ª•m t·ª´ 'kick ball' nghƒ©a l√† g√¨ kh√¥ng? It means to kick a ball.\t·ª™, t·ªõ bi·∫øt! N√≥ c√≥ nghƒ©a l√† ƒë√° b√≥ng.\tintent_positive\n",
    "Khi n√†o c·∫≠u th√≠ch 'kick ball'? Do you like to kick the ball in the park?\tT·ªõ th√≠ch ƒë√° b√≥ng v√†o bu·ªïi chi·ªÅu ·ªü c√¥ng vi√™n.\tintent_positive\n",
    "C·∫≠u c√≥ mu·ªën ch∆°i b√≥ng kh√¥ng? I don't want to play right now.\tKh√¥ng, t·ªõ kh√¥ng mu·ªën ch∆°i b√≥ng b√¢y gi·ªù.\tintent_negative\n",
    "C·∫≠u c√≥ th√≠ch ƒë√° b√≥ng kh√¥ng? I think it's fun!\tKh√¥ng, t·ªõ kh√¥ng th√≠ch ƒë√° b√≥ng l·∫Øm.\tintent_negative\n",
    "C·∫≠u c√≥ bi·∫øt c√°ch ƒë√° b√≥ng kh√¥ng? I'm not sure how to kick it.\tT·ªõ kh√¥ng ch·∫Øc l·∫Øm, nh∆∞ng t·ªõ s·∫Ω c·ªë g·∫Øng.\tintent_neutral\n",
    "C·∫≠u c√≥ th·ªÉ n√≥i l·∫°i c·ª•m t·ª´ 'kick ball' kh√¥ng? I want to hear you say it.\tKick ball.\tintent_neutral\n",
    "C·∫≠u c√≥ mu·ªën h·ªçc th√™m v·ªÅ c√°ch ƒë√° b√≥ng kh√¥ng? I can teach you more!\tC√≥, t·ªõ mu·ªën h·ªçc th√™m v·ªÅ c√°ch ƒë√° b√≥ng.\tintent_learn_more\n",
    "C·∫≠u c√≥ mu·ªën bi·∫øt th√™m v·ªÅ c√°c k·ªπ thu·∫≠t ƒë√° b√≥ng kh√¥ng? I can explain some techniques.\t·ª™, t·ªõ mu·ªën bi·∫øt th√™m v·ªÅ k·ªπ thu·∫≠t ƒë√° b√≥ng.\tintent_learn_more\n",
    "C·∫≠u c√≥ th·ªÉ n√≥i 'kick ball' b·∫±ng ti·∫øng Vi·ªát kh√¥ng? It's okay if you can't.\tT·ªõ kh√¥ng bi·∫øt n√≥i b·∫±ng ti·∫øng Vi·ªát.\tintent_fallback\n",
    "C·∫≠u c√≥ bi·∫øt ai l√† ng∆∞·ªùi gi·ªèi ƒë√° b√≥ng kh√¥ng? I don't know anyone.\tT·ªõ kh√¥ng bi·∫øt ai c·∫£.\tintent_fallback\n",
    "C·∫≠u c√≥ mu·ªën th·ª≠ n√≥i m·ªôt c√¢u v·ªõi 'kick ball' kh√¥ng? Maybe you can say, 'I kick the ball.'\t\tsilence\n",
    "C·∫≠u c√≥ th·ªÉ cho t·ªõ bi·∫øt c·∫≠u c√≥ th√≠ch ƒë√° b√≥ng kh√¥ng? Just say yes or no.\t\tsilence\n",
    "C·∫≠u c√≥ th√≠ch ch∆°i b√∫p b√™ kh√¥ng? Do you like to play with dolls?\tT·ªõ th√≠ch ch∆°i b√∫p b√™, n√≥ r·∫•t vui! I love playing with dolls, it's fun!\tintent_positive\n",
    "Ch∆°i b√∫p b√™ c√≥ th·ªÉ gi√∫p c·∫≠u h·ªçc g√¨? What can you learn from playing with dolls?\tT·ªõ kh√¥ng bi·∫øt, c√≥ th·ªÉ l√† s√°ng t·∫°o? I don't know, maybe creativity?\tintent_neutral\n",
    "N·∫øu c·∫≠u kh√¥ng th√≠ch ch∆°i b√∫p b√™, c·∫≠u th√≠ch g√¨? If you don't like playing with dolls, what do you like?\tT·ªõ kh√¥ng th√≠ch ch∆°i b√∫p b√™ l·∫Øm. I don't really like playing with dolls.\tintent_negative\n",
    "Ch∆°i b√∫p b√™ c√≥ th·ªÉ gi√∫p c·∫≠u giao ti·∫øp t·ªët h∆°n. Playing with dolls can help you communicate better.\tT·ªõ kh√¥ng ch·∫Øc l·∫Øm v·ªÅ ƒëi·ªÅu ƒë√≥. I'm not so sure about that.\tintent_neutral\n",
    "C·∫≠u c√≥ mu·ªën bi·∫øt th√™m v·ªÅ c√°ch ch∆°i b√∫p b√™ kh√¥ng? Do you want to learn more about how to play with dolls?\tC√≥, t·ªõ mu·ªën bi·∫øt th√™m! Yes, I want to learn more!\tintent_learn_more\n",
    "Ch∆°i b√∫p b√™ c√≥ th·ªÉ r·∫•t th√∫ v·ªã, nh∆∞ng t·ªõ kh√¥ng th√≠ch. Playing with dolls can be fun, but I don't like it.\tT·ªõ kh√¥ng mu·ªën n√≥i v·ªÅ b√∫p b√™ n·ªØa. I don't want to talk about dolls anymore.\tintent_negative\n",
    "C·∫≠u c√≥ th·ªÉ t·∫°o ra nhi·ªÅu c√¢u chuy·ªán khi ch∆°i b√∫p b√™. You can create many stories when playing with dolls.\tT·ªõ kh√¥ng bi·∫øt ph·∫£i b·∫Øt ƒë·∫ßu t·ª´ ƒë√¢u. I don't know where to start.\tintent_neutral\n",
    "C·∫≠u c√≥ bi·∫øt c√°ch t·∫°o m·ªôt c√¢u chuy·ªán v·ªõi b√∫p b√™ kh√¥ng? Do you know how to create a story with dolls?\tT·ªõ mu·ªën h·ªçc c√°ch l√†m ƒëi·ªÅu ƒë√≥! I want to learn how to do that!\tintent_learn_more\n",
    "N·∫øu c·∫≠u kh√¥ng c√≥ b√∫p b√™, c·∫≠u c√≥ th·ªÉ d√πng g√¨ kh√°c? If you don't have dolls, what can you use instead?\tT·ªõ kh√¥ng bi·∫øt, c√≥ th·ªÉ l√† th√∫ nh·ªìi b√¥ng? I don't know, maybe stuffed animals?\tintent_fallback\n",
    "Ch∆°i b√∫p b√™ c√≥ th·ªÉ gi√∫p c·∫≠u ph√°t tri·ªÉn k·ªπ nƒÉng x√£ h·ªôi. Playing with dolls can help you develop social skills.\tT·ªõ kh√¥ng th·∫•y ƒëi·ªÅu ƒë√≥ ƒë√∫ng. I don't think that's true.\tintent_negative\n",
    "C·∫≠u c√≥ th·ªÉ ch∆°i b√∫p b√™ v·ªõi b·∫°n b√® kh√¥ng? Can you play with dolls with your friends?\tT·ªõ kh√¥ng c√≥ b·∫°n ch∆°i c√πng. I don't have friends to play with.\tintent_fallback\n",
    "C·∫≠u c√≥ th·ªÉ t·∫°o ra m·ªôt nh√¢n v·∫≠t b√∫p b√™ th√∫ v·ªã. You can create an interesting doll character.\tT·ªõ kh√¥ng bi·∫øt l√†m th·∫ø n√†o ƒë·ªÉ t·∫°o nh√¢n v·∫≠t. I don't know how to create a character.\tintent_neutral\n",
    "C·∫≠u c√≥ mu·ªën th·ª≠ ch∆°i b√∫p b√™ kh√¥ng? Do you want to try playing with dolls?\tT·ªõ kh√¥ng ch·∫Øc l·∫Øm, nh∆∞ng c√≥ th·ªÉ th·ª≠. I'm not so sure, but I might try.\tintent_neutral\n",
    "C·∫≠u c√≥ bi·∫øt 'jump rope' l√† g√¨ kh√¥ng? It's a fun activity!\t·ª™, 'jump rope' l√† nh·∫£y d√¢y, t·ªõ th√≠ch l·∫Øm!\tintent_positive\n",
    "Nh·∫£y d√¢y r·∫•t t·ªët cho s·ª©c kh·ªèe! Do you jump rope often?\tT·ªõ kh√¥ng nh·∫£y nhi·ªÅu l·∫Øm, nh∆∞ng mu·ªën t·∫≠p h∆°n.\tintent_positive\n",
    "N·∫øu c·∫≠u kh√¥ng th√≠ch nh·∫£y d√¢y, c·∫≠u th√≠ch ho·∫°t ƒë·ªông n√†o kh√°c? What do you prefer?\tT·ªõ kh√¥ng th√≠ch nh·∫£y d√¢y, t·ªõ th√≠ch ch∆°i b√≥ng ƒë√° h∆°n.\tintent_negative\n",
    "Nh·∫£y d√¢y c√≥ th·ªÉ kh√≥ v·ªõi m·ªôt s·ªë ng∆∞·ªùi. Do you find it difficult?\t·ª™, t·ªõ th·∫•y kh√≥ l·∫Øm, t·ªõ kh√¥ng mu·ªën ti·∫øp t·ª•c.\tintent_negative\n",
    "C·∫≠u c√≥ bi·∫øt c√°ch nh·∫£y d√¢y ƒë√∫ng kh√¥ng? Do you know the right way to jump rope?\tT·ªõ kh√¥ng ch·∫Øc l·∫Øm, nh∆∞ng c√≥ th·ªÉ h·ªçc.\tintent_neutral\n",
    "Nh·∫£y d√¢y c√≥ th·ªÉ gi√∫p c·∫≠u kh·ªèe h∆°n! Are you interested in learning more?\tT·ªõ kh√¥ng bi·∫øt, nh∆∞ng c√≥ th·ªÉ th·ª≠.\tintent_neutral\n",
    "C·∫≠u c√≥ mu·ªën bi·∫øt th√™m v·ªÅ l·ª£i √≠ch c·ªßa nh·∫£y d√¢y kh√¥ng? Would you like to learn more about its benefits?\tC√≥, t·ªõ mu·ªën bi·∫øt th√™m v·ªÅ nh·∫£y d√¢y.\tintent_learn_more\n",
    "Nh·∫£y d√¢y gi√∫p tƒÉng c∆∞·ªùng s·ª©c b·ªÅn! Do you want to try it together?\tT·ªõ mu·ªën h·ªçc th√™m, nh∆∞ng kh√¥ng ch·∫Øc c√≥ th·ªÉ nh·∫£y t·ªët.\tintent_learn_more\n",
    "C·∫≠u c√≥ th·ªÉ nh·∫£y d√¢y ·ªü ƒë√¢u? Where can you jump rope?\tT·ªõ c√≥ th·ªÉ nh·∫£y ·ªü c√¥ng vi√™n, nh∆∞ng t·ªõ kh√¥ng mu·ªën.\tintent_fallback\n",
    "Nh·∫£y d√¢y c√≥ th·ªÉ vui l·∫Øm! What do you think about it?\tT·ªõ kh√¥ng bi·∫øt, c√≥ th·ªÉ t·ªõ s·∫Ω kh√¥ng nh·∫£y.\tintent_fallback\n",
    "C·∫≠u c√≥ mu·ªën th·ª≠ nh·∫£y d√¢y kh√¥ng? Would you like to give it a try?\t\tsilence\n",
    "Nh·∫£y d√¢y r·∫•t th√∫ v·ªã! Do you want to talk about it?\t\tsilence\n",
    "C·∫≠u c√≥ bi·∫øt c·ª•m t·ª´ 'Hold cup' nghƒ©a l√† g√¨ kh√¥ng? It means to hold a cup.\t·ª™, t·ªõ bi·∫øt! N√≥ c√≥ nghƒ©a l√† c·∫ßm c√°i c·ªëc.\tintent_positive\n",
    "Khi n√†o c·∫≠u th∆∞·ªùng 'hold cup'? When do you usually hold a cup?\tT·ªõ th∆∞·ªùng c·∫ßm c·ªëc khi u·ªëng tr√† v√†o bu·ªïi s√°ng.\tintent_positive\n",
    "C·∫≠u c√≥ th√≠ch c·∫ßm c·ªëc kh√¥ng? Do you like holding a cup?\tKh√¥ng, t·ªõ kh√¥ng th√≠ch l·∫Øm.\tintent_negative\n",
    "T·∫°i sao c·∫≠u kh√¥ng th√≠ch c·∫ßm c·ªëc? Why don't you like holding a cup?\tT·ªõ th·∫•y n√≥ h∆°i n·∫∑ng.\tintent_negative\n",
    "C·∫≠u c√≥ hi·ªÉu c√°ch s·ª≠ d·ª•ng 'hold cup' trong c√¢u kh√¥ng? Do you understand how to use 'hold cup' in a sentence?\tCh∆∞a ch·∫Øc l·∫Øm, t·ªõ kh√¥ng bi·∫øt.\tintent_neutral\n",
    "H√£y th·ª≠ n√≥i m·ªôt c√¢u v·ªõi 'hold cup'. Try to make a sentence with 'hold cup'.\tT·ªõ kh√¥ng bi·∫øt ph·∫£i n√≥i g√¨.\tintent_neutral\n",
    "C·∫≠u c√≥ mu·ªën h·ªçc th√™m v·ªÅ c√°ch s·ª≠ d·ª•ng 'hold cup' kh√¥ng? Do you want to learn more about using 'hold cup'?\tC√≥, t·ªõ mu·ªën bi·∫øt th√™m!\tintent_learn_more\n",
    "C·∫≠u mu·ªën bi·∫øt th√™m v·ªÅ c√°c c·ª•m t·ª´ kh√°c kh√¥ng? Do you want to learn more phrases?\tV√¢ng, t·ªõ mu·ªën h·ªçc nhi·ªÅu h∆°n.\tintent_learn_more\n",
    "C·∫≠u c√≥ th·ªÉ n√≥i 'hold cup' nh∆∞ng kh√¥ng bi·∫øt nghƒ©a kh√¥ng? Can you say 'hold cup' but not know the meaning?\tC√≥ th·ªÉ, nh∆∞ng t·ªõ kh√¥ng hi·ªÉu.\tintent_fallback\n",
    "N·∫øu c·∫≠u kh√¥ng bi·∫øt nghƒ©a, c·∫≠u c√≥ th·ªÉ n√≥i g√¨ kh√°c kh√¥ng? If you don't know the meaning, what else can you say?\tT·ªõ kh√¥ng bi·∫øt, c√≥ th·ªÉ l√† 'hello'?\tintent_fallback\n",
    "C·∫≠u c√≥ mu·ªën th·ª≠ n√≥i l·∫°i 'hold cup' kh√¥ng? Do you want to try saying 'hold cup' again?\t\tsilence\n",
    "C·∫≠u c√≥ nghe th·∫•y kh√¥ng? Do you hear me?\t\tsilence\n",
    "C·∫≠u c√≥ bi·∫øt c·ª•m t·ª´ 'wave hand' nghƒ©a l√† g√¨ kh√¥ng? It means to move your hand back and forth.\t·ª™, t·ªõ bi·∫øt! 'Wave hand' l√† v·∫´y tay.\tintent_positive\n",
    "Khi n√†o c·∫≠u th∆∞·ªùng 'wave hand'? Can you tell me a situation?\tT·ªõ th∆∞·ªùng v·∫´y tay khi ch√†o b·∫°n b√®.\tintent_positive\n",
    "C·∫≠u c√≥ th√≠ch v·∫´y tay kh√¥ng? Do you think it's fun?\tKh√¥ng, t·ªõ kh√¥ng th√≠ch l·∫Øm.\tintent_negative\n",
    "T·∫°i sao c·∫≠u kh√¥ng th√≠ch v·∫´y tay? Why do you feel that way?\tT·ªõ th·∫•y n√≥ h∆°i ng·ªõ ng·∫©n.\tintent_negative\n",
    "C·∫≠u c√≥ bi·∫øt c√°ch s·ª≠ d·ª•ng 'wave hand' trong c√¢u kh√¥ng? Can you make a sentence?\tT·ªõ kh√¥ng ch·∫Øc l·∫Øm.\tintent_neutral\n",
    "Kh√¥ng sao! H√£y th·ª≠ nh√©! 'I wave my hand to say hello.' Can you repeat that?\tT·ªõ th·ª≠ nh√©! 'I wave my hand to say hello.'\tintent_neutral\n",
    "C·∫≠u c√≥ mu·ªën h·ªçc th√™m v·ªÅ c√°c c·ª•m t·ª´ kh√°c kh√¥ng? Would you like to learn more phrases?\tC√≥, t·ªõ mu·ªën h·ªçc th√™m!\tintent_learn_more\n",
    "Tuy·ªát v·ªùi! C·∫≠u c√≥ mu·ªën bi·∫øt v·ªÅ 'shake hand' kh√¥ng? It's another gesture.\t·ª™, t·ªõ mu·ªën bi·∫øt v·ªÅ 'shake hand'.\tintent_learn_more\n",
    "C·∫≠u c√≥ th·ªÉ n√≥i 'wave hand' b·∫±ng ti·∫øng Vi·ªát kh√¥ng? Can you translate it?\tT·ªõ kh√¥ng bi·∫øt d·ªãch sao.\tintent_fallback\n",
    "Kh√¥ng sao! 'Wave hand' d·ªãch l√† 'v·∫´y tay'. Can you remember that?\tT·ªõ kh√¥ng ch·∫Øc l·∫Øm.\tintent_fallback\n",
    "C·∫≠u c√≥ mu·ªën th·ª≠ n√≥i 'I wave my hand' kh√¥ng? Can you say it?\t\tsilence\n",
    "C·∫≠u c√≥ nghe th·∫•y kh√¥ng? Can you try to say 'I wave my hand'?\t\tsilence\n",
    "C·∫≠u c√≥ th√≠ch ƒë·ªçc s√°ch kh√¥ng? I like to read books.\tT·ªõ th√≠ch ƒë·ªçc s√°ch, nh·∫•t l√† truy·ªán tranh.\tintent_positive\n",
    "S√°ch n√†o c·∫≠u th√≠ch nh·∫•t? My favorite book is...\tT·ªõ th√≠ch Harry Potter nh·∫•t.\tintent_positive\n",
    "C·∫≠u c√≥ mu·ªën ƒë·ªçc s√°ch kh√¥ng? I don't want to read right now.\tT·ªõ kh√¥ng mu·ªën ƒë·ªçc s√°ch b√¢y gi·ªù.\tintent_negative\n",
    "ƒê·ªçc s√°ch c√≥ th·ªÉ gi√∫p c·∫≠u h·ªçc nhi·ªÅu ƒëi·ªÅu m·ªõi. I don't like reading.\tT·ªõ kh√¥ng th√≠ch ƒë·ªçc s√°ch l·∫Øm.\tintent_negative\n",
    "C·∫≠u c√≥ bi·∫øt c√°ch ƒë·ªçc s√°ch hi·ªáu qu·∫£ kh√¥ng? I'm not sure about that.\tT·ªõ kh√¥ng ch·∫Øc l·∫Øm v·ªÅ c√°ch ƒë·ªçc s√°ch hi·ªáu qu·∫£.\tintent_neutral\n",
    "ƒê·ªçc s√°ch c√≥ th·ªÉ gi√∫p c·∫≠u th∆∞ gi√£n. I don't know what to read.\tT·ªõ kh√¥ng bi·∫øt n√™n ƒë·ªçc s√°ch g√¨.\tintent_neutral\n",
    "C·∫≠u c√≥ mu·ªën t√¨m hi·ªÉu th√™m v·ªÅ s√°ch kh√¥ng? I want to learn more about reading.\tT·ªõ mu·ªën t√¨m hi·ªÉu th√™m v·ªÅ c√°ch ch·ªçn s√°ch.\tintent_learn_more\n",
    "C√≥ nhi·ªÅu th·ªÉ lo·∫°i s√°ch kh√°c nhau. Can you tell me more?\tT·ªõ mu·ªën bi·∫øt th√™m v·ªÅ th·ªÉ lo·∫°i s√°ch khoa h·ªçc.\tintent_learn_more\n",
    "C·∫≠u c√≥ th·ªÉ ƒë·ªçc s√°ch ·ªü ƒë√¢u? I read books at home.\tT·ªõ th∆∞·ªùng ƒë·ªçc s√°ch ·ªü nh√†.\tintent_fallback\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### **L·ª±a ch·ªçn m√¥ h√¨nh**\n",
    "1. **N·∫øu t√†i nguy√™n h·∫°n ch·∫ø (RAM, GPU):**\n",
    "   - **BERT-base-multilingual-cased**: H·ªó tr·ª£ t·ªët ti·∫øng Anh v√† ti·∫øng Vi·ªát, k√≠ch th∆∞·ªõc nh·ªè h∆°n so v·ªõi XLM-R.\n",
    "   \n",
    "2. **N·∫øu c√≥ t√†i nguy√™n m·∫°nh m·∫Ω:**\n",
    "   - **XLM-Roberta-large**: Hi·ªáu su·∫•t v∆∞·ª£t tr·ªôi cho b√†i to√°n ƒëa ng√¥n ng·ªØ.\n",
    "\n",
    "3. **Khi c·∫ßn t·ªëi ∆∞u SOTA:**\n",
    "   - **mT5-base** ho·∫∑c **mT5-large**: H·ªó tr·ª£ ƒëa ng√¥n ng·ªØ v√† ho·∫°t ƒë·ªông t·ªët tr√™n d·ªØ li·ªáu ng·ªØ c·∫£nh ng·∫Øn.\n",
    "\n",
    "---\n",
    "\n",
    "### **K·∫ø ho·∫°ch th·ª≠ nghi·ªám**\n",
    "1. **Ch·∫°y th·ª≠ c·∫£ hai ph∆∞∆°ng ph√°p**:\n",
    "   - Ph∆∞∆°ng ph√°p 1: `combined_text = question + \" [SEP] \" + answer`.\n",
    "   - Ph∆∞∆°ng ph√°p 2: `combined_text = \"[CLS] \" + question + \" [SEP] \" + answer + \" [SEP]\"`.\n",
    "\n",
    "2. **So s√°nh k·∫øt qu·∫£ tr√™n t·∫≠p ki·ªÉm tra**:\n",
    "   - **Metric**: Accuracy, F1-score.\n",
    "   - **Th·ªùi gian x·ª≠ l√Ω**: T√≠nh th·ªùi gian hu·∫•n luy·ªán v√† inference.\n",
    "\n",
    "3. **Ch·ªçn ph∆∞∆°ng ph√°p c√≥ k·∫øt qu·∫£ t·ªët h∆°n**:\n",
    "   - ∆Øu ti√™n ph∆∞∆°ng ph√°p c√≥ F1-score cao h∆°n v√† x·ª≠ l√Ω nhanh h∆°n.\n",
    "\n",
    "N·∫øu c·∫ßn h·ªó tr·ª£ tri·ªÉn khai th·ª≠ nghi·ªám chi ti·∫øt, h√£y cho m√¨nh bi·∫øt nh√©! üòä"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D∆∞·ªõi ƒë√¢y l√† b·∫£ng so s√°nh chi ti·∫øt c√°c m√¥ h√¨nh ph√π h·ª£p v·ªõi b√†i to√°n c·ªßa b·∫°n:\n",
    "\n",
    "| **M√¥ h√¨nh**           | **∆Øu ƒëi·ªÉm**                                                                                      | **Nh∆∞·ª£c ƒëi·ªÉm**                                                                                | **Ph√π h·ª£p**                                   |\n",
    "|-----------------------|------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------|-----------------------------------------------|\n",
    "| **PhoBERT**           | - T·ªëi ∆∞u cho ti·∫øng Vi·ªát.                                                                       | - Kh√¥ng h·ªó tr·ª£ ti·∫øng Anh.                                                                   | - B√†i to√°n ch·ªâ t·∫≠p trung v√†o ti·∫øng Vi·ªát.      |\n",
    "|                       | - Hi·ªáu qu·∫£ cao cho ph√¢n lo·∫°i vƒÉn b·∫£n, c·∫£m x√∫c.                                                 | - C·∫ßn x·ª≠ l√Ω ri√™ng d·ªØ li·ªáu ti·∫øng Anh n·∫øu c√≥.                                                 |                                               |\n",
    "| **BERTweet**          | - T·ªëi ∆∞u h√≥a cho ti·∫øng Anh kh√¥ng ch√≠nh th·ª©c (h·ªôi tho·∫°i, m·∫°ng x√£ h·ªôi).                          | - Kh√¥ng h·ªó tr·ª£ ti·∫øng Vi·ªát.                                                                  | - B√†i to√°n ch·ªâ t·∫≠p trung v√†o ti·∫øng Anh.       |\n",
    "|                       | - Hi·ªáu qu·∫£ t·ªët cho vƒÉn b·∫£n phi ch√≠nh th·ª©c.                                                     | - C·∫ßn x·ª≠ l√Ω ri√™ng d·ªØ li·ªáu ti·∫øng Vi·ªát n·∫øu c√≥.                                                 |                                               |\n",
    "| **mBERT**             | - H·ªó tr·ª£ ƒëa ng√¥n ng·ªØ (c·∫£ ti·∫øng Anh v√† ti·∫øng Vi·ªát).                                             | - Hi·ªáu su·∫•t th·∫•p h∆°n so v·ªõi PhoBERT (cho ti·∫øng Vi·ªát) ho·∫∑c BERTweet (cho ti·∫øng Anh).          | - B√†i to√°n c·∫ßn h·ªó tr·ª£ song ng·ªØ c∆° b·∫£n.        |\n",
    "|                       | - Kh√¥ng c·∫ßn t√°ch d·ªØ li·ªáu ng√¥n ng·ªØ.                                                             |                                                                                             |                                               |\n",
    "| **XLM-R (XLM-RoBERTa)** | - M·∫°nh m·∫Ω h∆°n mBERT trong x·ª≠ l√Ω ng√¥n ng·ªØ ƒëa ng·ªØ.                                               | - Y√™u c·∫ßu t√†i nguy√™n l·ªõn h∆°n (RAM, GPU, th·ªùi gian hu·∫•n luy·ªán).                              | - B√†i to√°n song ng·ªØ v√† c√≥ t√†i nguy√™n t·ªët.     |\n",
    "|                       | - Hi·ªáu qu·∫£ t·ªët tr√™n ng·ªØ c·∫£nh ti·∫øng Anh v√† ti·∫øng Vi·ªát.                                          |                                                                                             |                                               |\n",
    "| **K·∫øt h·ª£p PhoBERT + BERTweet** | - T·ªëi ∆∞u h√≥a cao nh·∫•t cho t·ª´ng ng√¥n ng·ªØ (PhoBERT cho ti·∫øng Vi·ªát, BERTweet cho ti·∫øng Anh).  | - Y√™u c·∫ßu nhi·ªÅu t√†i nguy√™n, th·ªùi gian x·ª≠ l√Ω ph·ª©c t·∫°p h∆°n (t√°ch v√† h·ª£p nh·∫•t k·∫øt qu·∫£).         | - B√†i to√°n song ng·ªØ c·∫ßn ƒë·ªô ch√≠nh x√°c cao.     |\n",
    "\n",
    "### **G·ª£i √Ω s·ª≠ d·ª•ng**\n",
    "- **PhoBERT ho·∫∑c BERTweet**: N·∫øu d·ªØ li·ªáu ch·ªâ s·ª≠ d·ª•ng m·ªôt ng√¥n ng·ªØ (ti·∫øng Vi·ªát ho·∫∑c ti·∫øng Anh).\n",
    "- **mBERT**: Khi c·∫ßn x·ª≠ l√Ω song ng·ªØ m√† kh√¥ng mu·ªën ph·ª©c t·∫°p h√≥a pipeline.\n",
    "- **XLM-R**: Khi c√≥ ƒë·ªß t√†i nguy√™n v√† mu·ªën m√¥ h√¨nh ƒëa ng·ªØ m·∫°nh m·∫Ω.\n",
    "- **PhoBERT + BERTweet**: Khi c·∫ßn ƒë·ªô ch√≠nh x√°c cao nh·∫•t v√† ch·∫•p nh·∫≠n vi·ªác x·ª≠ l√Ω ph·ª©c t·∫°p.\n",
    "\n",
    "H√£y ch·ªçn m√¥ h√¨nh t√πy thu·ªôc v√†o **t√†i nguy√™n**, **ƒë·ªô ph·ª©c t·∫°p ch·∫•p nh·∫≠n ƒë∆∞·ª£c**, v√† **y√™u c·∫ßu ch√≠nh x√°c c·ªßa b√†i to√°n**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ph√¢n t√≠ch v√† ch·ªçn **method t·ªët nh·∫•t**\n",
    "\n",
    "D·ª±a tr√™n b√†i to√°n v√† c√°c y√™u c·∫ßu:\n",
    "\n",
    "1. **D·ªØ li·ªáu l√† h·ªôi tho·∫°i ng·∫Øn v·ªõi c√°c ph·∫£n h·ªìi ƒëa d·∫°ng, c·∫ßn ph√¢n lo·∫°i √Ω ƒë·ªãnh (intent).**\n",
    "2. **Y√™u c·∫ßu kh√¥ng h·∫°n ch·∫ø t√†i nguy√™n, t√¨m ph∆∞∆°ng ph√°p c√≥ hi·ªáu su·∫•t cao nh·∫•t.**\n",
    "3. **Ng√¥n ng·ªØ l√† ti·∫øng Vi·ªát v√† ti·∫øng Anh v·ªõi c√°c m·∫´u ƒë∆°n gi·∫£n nh∆∞ng c√≥ y·∫øu t·ªë ng·ªØ c·∫£nh.**\n",
    "\n",
    "---\n",
    "\n",
    "### **Ph∆∞∆°ng ph√°p t·ªët nh·∫•t: PhoBERT + Meta-learning approach**\n",
    "\n",
    "| **Th√†nh ph·∫ßn**                 | **Chi ti·∫øt l·ª±a ch·ªçn**                                                                                                                                                                                                                                     |\n",
    "|--------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| **M√¥ h√¨nh x·ª≠ l√Ω ch√≠nh**         | PhoBERT (cho ti·∫øng Vi·ªát) v√† m·ªôt ki·∫øn tr√∫c Transformer-based (BERTweet ho·∫∑c RoBERTa) cho ti·∫øng Anh. PhoBERT ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a ƒë·ªÉ l√†m vi·ªác v·ªõi ti·∫øng Vi·ªát, trong khi BERTweet hi·ªáu qu·∫£ v·ªõi ng·ªØ li·ªáu phi ch√≠nh th·ªëng (h·ªôi tho·∫°i, m·∫°ng x√£ h·ªôi).                                                    |\n",
    "| **Fine-tuning**                | Fine-tune PhoBERT v√† BERTweet v·ªõi d·ªØ li·ªáu hu·∫•n luy·ªán h·ªôi tho·∫°i c·ªßa b·∫°n. T√°ch t·ª´ng ph·∫ßn d·ªØ li·ªáu ng√¥n ng·ªØ ƒë·ªÉ hu·∫•n luy·ªán ri√™ng, ƒë·∫£m b·∫£o m√¥ h√¨nh h·ªçc ƒë∆∞·ª£c c√°c ƒë·∫∑c tr∆∞ng ph√π h·ª£p nh·∫•t.                                                                         |\n",
    "| **K·∫øt h·ª£p ƒë·∫ßu ra**              | S·ª≠ d·ª•ng m·ªôt **meta-classifier** (logistic regression ho·∫∑c feedforward neural network) ƒë·ªÉ k·∫øt h·ª£p ƒë·∫ßu ra t·ª´ PhoBERT v√† BERTweet, t·∫°o ra nh√£n ph√¢n lo·∫°i cu·ªëi c√πng.                                                                                          |\n",
    "| **T√≠ch h·ª£p ng·ªØ c·∫£nh**           | S·ª≠ d·ª•ng **multi-turn context encoding**: Thay v√¨ ph√¢n lo·∫°i m·ªói c√¢u ƒë·ªôc l·∫≠p, k·∫øt h·ª£p ng·ªØ c·∫£nh c·ªßa c√°c c√¢u tr∆∞·ªõc ƒë√≥ ƒë·ªÉ c·∫£i thi·ªán ƒë·ªô ch√≠nh x√°c. BERT-based models h·ªó tr·ª£ ph∆∞∆°ng ph√°p n√†y th√¥ng qua encoding nhi·ªÅu c√¢u th√†nh m·ªôt chu·ªói.                            |\n",
    "| **X·ª≠ l√Ω c√°c intent \"silence\"**  | √Åp d·ª•ng k·ªπ thu·∫≠t **imbalanced data handling** (focal loss ho·∫∑c oversampling) cho c√°c l·ªõp hi·∫øm, nh∆∞ intent \"silence\".                                                                                                                                     |\n",
    "| **Ph√¢n b·ªï t√†i nguy√™n**          | Hu·∫•n luy·ªán tr√™n GPU m·∫°nh (A100 ho·∫∑c V100), batch size l·ªõn (~64), learning rate th·∫•p (1e-5), v√† epochs (~10-15) ƒë·ªÉ ƒë·∫°t hi·ªáu su·∫•t t·ªëi ƒëa.                                                                                                                 |\n",
    "| **ƒê√°nh gi√° v√† t·ªëi ∆∞u**          | S·ª≠ d·ª•ng **cross-validation** tr√™n t·∫≠p d·ªØ li·ªáu ƒë·ªÉ ƒë√°nh gi√° F1-score, Precision, Recall. T·∫≠p trung t·ªëi ∆∞u h√≥a F1-score v√¨ ƒë√¢y l√† b√†i to√°n ph√¢n lo·∫°i v·ªõi c√°c l·ªõp quan tr·ªçng nh∆∞ intent_positive v√† intent_negative.                                          |\n",
    "\n",
    "---\n",
    "\n",
    "### **L√Ω do l·ª±a ch·ªçn**\n",
    "1. **PhoBERT v√† BERTweet l√† SOTA (State of the Art):** \n",
    "   - PhoBERT d·∫´n ƒë·∫ßu trong c√°c b√†i to√°n ti·∫øng Vi·ªát.\n",
    "   - BERTweet m·∫°nh m·∫Ω cho d·ªØ li·ªáu ti·∫øng Anh kh√¥ng ch√≠nh th·ª©c.\n",
    "   \n",
    "2. **T·ªëi ∆∞u h√≥a x·ª≠ l√Ω h·ªôi tho·∫°i:**\n",
    "   - X·ª≠ l√Ω ƒë∆∞·ª£c h·ªôi tho·∫°i ƒëa ng·ªØ.\n",
    "   - K·∫øt h·ª£p ng·ªØ c·∫£nh (context encoding) gi√∫p tƒÉng ƒë·ªô ch√≠nh x√°c cho c√°c c√¢u li√™n quan.\n",
    "\n",
    "3. **Kh√¥ng gi·ªõi h·∫°n t√†i nguy√™n:**\n",
    "   - Ph∆∞∆°ng ph√°p k·∫øt h·ª£p nhi·ªÅu m√¥ h√¨nh v√† fine-tuning t·ªëi ∆∞u y√™u c·∫ßu nhi·ªÅu t√†i nguy√™n, ph√π h·ª£p v·ªõi b√†i to√°n c·ªßa b·∫°n.\n",
    "\n",
    "---\n",
    "\n",
    "### K·ª≥ v·ªçng hi·ªáu su·∫•t\n",
    "- **F1-score t·ªïng quan**: > 92%.\n",
    "- **X·ª≠ l√Ω t·ªët c√°c l·ªõp hi·∫øm nh∆∞ intent_fallback, intent_learn_more, v√† silence.**\n",
    "- **Th·ªùi gian inference**: T·ªëi ∆∞u h√≥a ƒë·ªÉ inference nhanh (~50ms m·ªói m·∫´u tr√™n GPU)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D∆∞·ªõi ƒë√¢y l√† b·∫£ng so s√°nh c√°c m√¥ h√¨nh ph·ªï bi·∫øn cho b√†i to√°n **Sequence Classification**, t·∫≠p trung v√†o nh·ªØng y·∫øu t·ªë nh∆∞ k√≠ch th∆∞·ªõc, t·ªëc ƒë·ªô, hi·ªáu su·∫•t, v√† c√°c tr∆∞·ªùng h·ª£p s·ª≠ d·ª•ng:\n",
    "\n",
    "| **M√¥ h√¨nh**          | **S·ªë tham s·ªë** | **K√≠ch th∆∞·ªõc (MB)** | **Ng√¥n ng·ªØ h·ªó tr·ª£**       | **∆Øu ƒëi·ªÉm**                                                                 | **Nh∆∞·ª£c ƒëi·ªÉm**                                                                                 | **·ª®ng d·ª•ng ph·ªï bi·∫øn**                                           |\n",
    "|-----------------------|----------------|----------------------|---------------------------|-----------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------|----------------------------------------------------------------|\n",
    "| **BERT**             | ~110M         | ~450                | Ti·∫øng Anh                | - Hi·ªáu su·∫•t t·ªët tr√™n nhi·ªÅu nhi·ªám v·ª•.                                        | - K√≠ch th∆∞·ªõc l·ªõn, c·∫ßn t√†i nguy√™n t√≠nh to√°n cao.                                                | Ph√¢n lo·∫°i vƒÉn b·∫£n, ph√¢n t√≠ch c·∫£m x√∫c, QA.                      |\n",
    "| **DistilBERT**       | ~66M          | ~250                | Ti·∫øng Anh                | - Nh·∫π h∆°n BERT, nhanh h∆°n ~60%.                                            | - Hi·ªáu su·∫•t gi·∫£m nh·∫π so v·ªõi BERT.                                                              | Chatbot, ph√¢n lo·∫°i √Ω ƒë·ªãnh, g·ª£i √Ω t·ª± ƒë·ªông.                      |\n",
    "| **PhoBERT**          | ~135M         | ~500                | Ti·∫øng Vi·ªát               | - ƒê∆∞·ª£c t·ªëi ∆∞u h√≥a cho ti·∫øng Vi·ªát.                                           | - Ch·ªâ h·ªó tr·ª£ ti·∫øng Vi·ªát.                                                                       | Ph√¢n lo·∫°i c·∫£m x√∫c, ph√¢n t√≠ch √Ω ƒë·ªãnh ti·∫øng Vi·ªát.                |\n",
    "| **XLM-RoBERTa**      | ~125M         | ~550                | ƒêa ng√¥n ng·ªØ (100+)       | - T·ªët cho c√°c nhi·ªám v·ª• ƒëa ng√¥n ng·ªØ.                                         | - K√≠ch th∆∞·ªõc l·ªõn, c·∫ßn nhi·ªÅu t√†i nguy√™n.                                                        | D·ªãch m√°y, nh·∫≠n d·∫°ng th·ª±c th·ªÉ (NER), QA.                        |\n",
    "| **BERTweet**         | ~135M         | ~500                | Ti·∫øng Anh                | - T·ªëi ∆∞u cho d·ªØ li·ªáu t·ª´ Twitter.                                            | - Ch·ªâ hi·ªáu qu·∫£ tr√™n d·ªØ li·ªáu kh√¥ng ch√≠nh th·ª©c, v√≠ d·ª• nh∆∞ Twitter.                              | Ph√¢n t√≠ch c·∫£m x√∫c m·∫°ng x√£ h·ªôi, nh·∫≠n d·∫°ng ch·ªß ƒë·ªÅ.               |\n",
    "| **ALBERT**           | ~12M          | ~40                 | Ti·∫øng Anh                | - Nh·∫π h∆°n BERT, nhanh h∆°n nhi·ªÅu l·∫ßn.                                        | - Hi·ªáu su·∫•t gi·∫£m tr√™n d·ªØ li·ªáu l·ªõn h∆°n ho·∫∑c ph·ª©c t·∫°p.                                           | Ph√¢n t√≠ch c·∫£m x√∫c, g·ª£i √Ω vƒÉn b·∫£n.                              |\n",
    "| **ELECTRA**          | ~14M          | ~50                 | Ti·∫øng Anh                | - Hu·∫•n luy·ªán nhanh h∆°n BERT v·ªõi chi ph√≠ th·∫•p h∆°n.                           | - Hi·ªáu su·∫•t kh√¥ng v∆∞·ª£t tr·ªôi tr√™n t·∫•t c·∫£ c√°c nhi·ªám v·ª•.                                          | Ph√¢n lo·∫°i vƒÉn b·∫£n, ph√¢n t√≠ch c·∫£m x√∫c.                          |\n",
    "| **mBERT (Multilingual BERT)** | ~110M         | ~450                | ƒêa ng√¥n ng·ªØ (100+)       | - T·ªët cho c√°c t√°c v·ª• ƒëa ng√¥n ng·ªØ c∆° b·∫£n.                                    | - Kh√¥ng ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a cho ng√¥n ng·ªØ c·ª• th·ªÉ.                                                  | D·ªãch m√°y, QA, ph√¢n t√≠ch vƒÉn b·∫£n ƒëa ng√¥n ng·ªØ.                   |\n",
    "| **RoBERTa**          | ~125M         | ~550                | Ti·∫øng Anh                | - C·∫£i thi·ªán hi·ªáu su·∫•t nh·ªù hu·∫•n luy·ªán v·ªõi l∆∞·ª£ng d·ªØ li·ªáu l·ªõn h∆°n BERT.         | - K√≠ch th∆∞·ªõc l·ªõn, t·ªëc ƒë·ªô ch·∫≠m h∆°n BERT.                                                       | QA, ph√¢n t√≠ch c√∫ ph√°p, ph√¢n t√≠ch vƒÉn b·∫£n ph·ª©c t·∫°p.             |\n",
    "| **GPT-based models** | ~175B         | > 70000             | Ti·∫øng Anh, ƒëa ng√¥n ng·ªØ   | - T·ªët cho nhi·ªÅu nhi·ªám v·ª•, bao g·ªìm c·∫£ s√°ng t·∫°o n·ªôi dung v√† ph√¢n lo·∫°i vƒÉn b·∫£n. | - C·ª±c k·ª≥ n·∫∑ng, c·∫ßn GPU m·∫°nh, chi ph√≠ hu·∫•n luy·ªán v√† tri·ªÉn khai cao.                            | S√°ng t·∫°o n·ªôi dung, vi·∫øt vƒÉn b·∫£n t·ª± ƒë·ªông, chatbot n√¢ng cao.      |\n",
    "\n",
    "### K·∫øt lu·∫≠n:\n",
    "- **N·∫øu t√†i nguy√™n gi·ªõi h·∫°n:** S·ª≠ d·ª•ng **DistilBERT** ho·∫∑c **ALBERT**.\n",
    "- **N·∫øu c·∫ßn x·ª≠ l√Ω ti·∫øng Vi·ªát:** Ch·ªçn **PhoBERT**.\n",
    "- **N·∫øu c·∫ßn m√¥ h√¨nh ƒëa ng√¥n ng·ªØ:** **XLM-RoBERTa** ho·∫∑c **mBERT** l√† l·ª±a ch·ªçn t·ªët.\n",
    "- **N·∫øu c·∫ßn x·ª≠ l√Ω m·∫°ng x√£ h·ªôi:** **BERTweet** ph√π h·ª£p cho c√°c ngu·ªìn d·ªØ li·ªáu nh∆∞ Twitter.\n",
    "- **N·∫øu y√™u c·∫ßu hi·ªáu su·∫•t cao:** **RoBERTa** ho·∫∑c **ELECTRA** c√≥ th·ªÉ l√† l·ª±a ch·ªçn t·ªëi ∆∞u."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### H·ªèi th√™m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "anh @Hoang Xuan To  ∆°i, model t·∫ßm <500MB m√† t·ªët cho c·∫£ ti·∫øng anh, ti·∫øng vi·ªát hi·ªán nay cho task Classification anh c√≥ recommend con n√†o kh√¥ng ·∫°. (mBERT, XLM-RoBERTa, ... ) ·∫°. [∆Øu ti√™n acc anh ·∫°]\n",
    "---\n",
    "Input: question_robot - user_answer - user_intent_label: \n",
    "Sample Data: \n",
    "```\n",
    "robot\tuser_answer\tuser_intent\n",
    "C·∫≠u c√≥ mu·ªën h·ªçc th√™m v·ªÅ c√°c c·ª•m t·ª´ kh√°c kh√¥ng? Maybe something like 'Run fast'?\tKh√¥ng, t·ªõ kh√¥ng mu·ªën h·ªçc th√™m ƒë√¢u.\tintent_negative\n",
    "C·∫≠u c√≥ hi·ªÉu c√°ch s·ª≠ d·ª•ng 'Jump now' kh√¥ng? Do you feel confident using it?\tT·ªõ kh√¥ng bi·∫øt, c√≥ th·ªÉ t·ªõ c·∫ßn th√™m th·ªùi gian.\tintent_neutral\n",
    "C·∫≠u c√≥ th·ªÉ n√≥i l·∫°i c√¢u 'Jump now' kh√¥ng? Can you repeat it?\tT·ªõ kh√¥ng ch·∫Øc l·∫Øm, nh∆∞ng t·ªõ s·∫Ω th·ª≠.\tintent_neutral\n",
    "C·∫≠u c√≥ mu·ªën t√¨m hi·ªÉu th√™m v·ªÅ c√°c ƒë·ªông t·ª´ h√†nh ƒë·ªông kh√¥ng? Like 'jump'?\tC√≥, t·ªõ mu·ªën bi·∫øt th√™m v·ªÅ c√°c ƒë·ªông t·ª´ kh√°c.\tintent_learn_more\n",
    "C·∫≠u c√≥ mu·ªën h·ªçc c√°ch k·∫øt h·ª£p 'Jump now' v·ªõi c√°c c√¢u kh√°c kh√¥ng? For example, 'Jump now and have fun!'\t·ª™, t·ªõ mu·ªën h·ªçc th√™m v·ªÅ c√°ch k·∫øt h·ª£p.\tintent_learn_more\n",
    "C·∫≠u c√≥ th·ªÉ n√≥i 'Jump now' b·∫±ng ti·∫øng Vi·ªát kh√¥ng? Can you translate it?\tT·ªõ kh√¥ng bi·∫øt, c√≥ th·ªÉ l√† 'Nh·∫£y ngay'.\tintent_fallback\n",
    "C·∫≠u c√≥ nghƒ© r·∫±ng 'Jump now' l√† m·ªôt c√¢u kh√≥ kh√¥ng? Is it difficult for you?\tT·ªõ kh√¥ng bi·∫øt, c√≥ th·ªÉ l√† d·ªÖ.\tintent_fallback\n",
    "C·∫≠u c√≥ mu·ªën th·ª≠ n√≥i 'Jump now' ngay b√¢y gi·ªù kh√¥ng? Can you say it out loud?\t\tsilence\n",
    "C·∫≠u c√≥ mu·ªën c√πng t·ªõ th·ª±c h√†nh c√¢u n√†y kh√¥ng? Let's practice 'Jump now' together!\t\tsilence\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tui ƒëang l√†m task nh∆∞ n√†y : \n",
    "----\n",
    "\n",
    "model t·∫ßm <500MB m√† t·ªët cho c·∫£ ti·∫øng anh, ti·∫øng vi·ªát hi·ªán nay cho task Classification \n",
    "\n",
    "th√¨ √¥ng c√≥ con n√†o kh√¥ng, recommend t√¥i v·ªõi. (mBERT, XLM-RoBERTa, ... ) ·∫°. [∆Øu ti√™n accuracy]\n",
    "---\n",
    "Input: question_robot - user_answer - user_intent_label: \n",
    "Sample Data: \n",
    "```\n",
    "robot\tuser_answer\tuser_intent\n",
    "C·∫≠u c√≥ mu·ªën h·ªçc th√™m v·ªÅ c√°c c·ª•m t·ª´ kh√°c kh√¥ng? Maybe something like 'Run fast'?\tKh√¥ng, t·ªõ kh√¥ng mu·ªën h·ªçc th√™m ƒë√¢u.\tintent_negative\n",
    "C·∫≠u c√≥ hi·ªÉu c√°ch s·ª≠ d·ª•ng 'Jump now' kh√¥ng? Do you feel confident using it?\tT·ªõ kh√¥ng bi·∫øt, c√≥ th·ªÉ t·ªõ c·∫ßn th√™m th·ªùi gian.\tintent_neutral\n",
    "C·∫≠u c√≥ th·ªÉ n√≥i l·∫°i c√¢u 'Jump now' kh√¥ng? Can you repeat it?\tT·ªõ kh√¥ng ch·∫Øc l·∫Øm, nh∆∞ng t·ªõ s·∫Ω th·ª≠.\tintent_neutral\n",
    "C·∫≠u c√≥ mu·ªën t√¨m hi·ªÉu th√™m v·ªÅ c√°c ƒë·ªông t·ª´ h√†nh ƒë·ªông kh√¥ng? Like 'jump'?\tC√≥, t·ªõ mu·ªën bi·∫øt th√™m v·ªÅ c√°c ƒë·ªông t·ª´ kh√°c.\tintent_learn_more\n",
    "C·∫≠u c√≥ mu·ªën h·ªçc c√°ch k·∫øt h·ª£p 'Jump now' v·ªõi c√°c c√¢u kh√°c kh√¥ng? For example, 'Jump now and have fun!'\t·ª™, t·ªõ mu·ªën h·ªçc th√™m v·ªÅ c√°ch k·∫øt h·ª£p.\tintent_learn_more\n",
    "C·∫≠u c√≥ th·ªÉ n√≥i 'Jump now' b·∫±ng ti·∫øng Vi·ªát kh√¥ng? Can you translate it?\tT·ªõ kh√¥ng bi·∫øt, c√≥ th·ªÉ l√† 'Nh·∫£y ngay'.\tintent_fallback\n",
    "C·∫≠u c√≥ nghƒ© r·∫±ng 'Jump now' l√† m·ªôt c√¢u kh√≥ kh√¥ng? Is it difficult for you?\tT·ªõ kh√¥ng bi·∫øt, c√≥ th·ªÉ l√† d·ªÖ.\tintent_fallback\n",
    "C·∫≠u c√≥ mu·ªën th·ª≠ n√≥i 'Jump now' ngay b√¢y gi·ªù kh√¥ng? Can you say it out loud?\t\tsilence\n",
    "C·∫≠u c√≥ mu·ªën c√πng t·ªõ th·ª±c h√†nh c√¢u n√†y kh√¥ng? Let's practice 'Jump now' together!\t\tsilence\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D∆∞·ªõi ƒë√¢y l√† b·∫£ng so s√°nh chi ti·∫øt gi·ªØa **mBERT**, **XLM-RoBERTa**, v√† **ProphetNet** khi √°p d·ª•ng v√†o b√†i to√°n ph√¢n lo·∫°i ng·ªØ nghƒ©a (classification) nh∆∞ b·∫°n m√¥ t·∫£:\n",
    "\n",
    "---\n",
    "\n",
    "| **Ti√™u ch√≠**                  | **mBERT**                                  | **XLM-RoBERTa**                              | **ProphetNet**                              |\n",
    "|--------------------------------|--------------------------------------------|---------------------------------------------|---------------------------------------------|\n",
    "| **Ki·∫øn tr√∫c**                 | Transformer                               | Transformer                                 | Transformer + Future N-Gram Prediction     |\n",
    "| **D·ªØ li·ªáu hu·∫•n luy·ªán**        | Wikipedia (104 ng√¥n ng·ªØ)                  | CommonCrawl (100 ng√¥n ng·ªØ, d·ªØ li·ªáu l·ªõn h∆°n) | Custom Dataset cho Text Generation         |\n",
    "| **T·ªëi ∆∞u h√≥a task n√†o?**      | Ph√¢n lo·∫°i (Classification)                | Ph√¢n lo·∫°i (Classification)                 | Sinh ng·ªØ c·∫£nh t∆∞∆°ng lai (Text Generation)  |\n",
    "| **Hi·ªáu su·∫•t Classification** | T·ªët, ph√π h·ª£p cho ƒëa ng√¥n ng·ªØ c∆° b·∫£n.       | T·ªët h∆°n mBERT nh·ªù d·ªØ li·ªáu phong ph√∫ h∆°n.   | Kh√¥ng t·ªëi ∆∞u cho classification tasks.     |\n",
    "| **Ng√¥n ng·ªØ h·ªó tr·ª£**           | 104                                       | 100                                         | T·∫≠p trung v√†o ti·∫øng Anh.                   |\n",
    "| **K√≠ch th∆∞·ªõc m√¥ h√¨nh**        | ~450MB                                    | ~550MB                                      | ~570MB                                      |\n",
    "| **Kh·∫£ nƒÉng x·ª≠ l√Ω song ng·ªØ (EN-VI)** | ·ªîn ƒë·ªãnh nh∆∞ng kh√¥ng t·ªët b·∫±ng XLM-RoBERTa. | T·ªët h∆°n nh·ªù d·ªØ li·ªáu ƒëa d·∫°ng.               | Kh√¥ng ph√π h·ª£p cho ƒëa ng√¥n ng·ªØ.             |\n",
    "| **∆Øu ƒëi·ªÉm**                   | Nh·∫π, ph·ªï bi·∫øn, ti·∫øt ki·ªám t√†i nguy√™n.      | Hi·ªáu su·∫•t cao, t·ªïng qu√°t t·ªët tr√™n d·ªØ li·ªáu ph·ª©c t·∫°p. | Sinh ng·ªØ c·∫£nh ch√≠nh x√°c, t·ªët cho QA v√† summarization. |\n",
    "| **Nh∆∞·ª£c ƒëi·ªÉm**                | T·ªïng qu√°t k√©m tr√™n d·ªØ li·ªáu l·ªõn.           | Y√™u c·∫ßu t√†i nguy√™n t√≠nh to√°n cao h∆°n mBERT. | Kh√¥ng ph√π h·ª£p cho classification.          |\n",
    "| **Th·ªùi gian inference**       | Nhanh h∆°n XLM-RoBERTa, ProphetNet.        | Ch·∫≠m h∆°n mBERT, nh∆∞ng nhanh h∆°n ProphetNet. | Ch·∫≠m nh·∫•t do c·∫•u tr√∫c d·ª± ƒëo√°n t∆∞∆°ng lai.   |\n",
    "| **ƒê·ªô ch√≠nh x√°c (EN-VI Classification)** | Kh√° t·ªët (nh∆∞ng d·ªÖ b·ªã overfitting).         | T·ªët nh·∫•t nh·ªù t√≠nh ƒëa d·∫°ng d·ªØ li·ªáu.         | Kh√¥ng ph√π h·ª£p do kh√¥ng t·ªëi ∆∞u classification.|\n",
    "\n",
    "---\n",
    "\n",
    "### ƒê√°nh gi√° chi ti·∫øt:\n",
    "\n",
    "#### **1. mBERT**:\n",
    "- **∆Øu ƒëi·ªÉm**: Nh·∫π, ph·ªï bi·∫øn, d·ªÖ tri·ªÉn khai. Ti·∫øt ki·ªám t√†i nguy√™n.\n",
    "- **Nh∆∞·ª£c ƒëi·ªÉm**: Kh·∫£ nƒÉng t·ªïng qu√°t v√† ƒë·ªô ch√≠nh x√°c k√©m h∆°n XLM-RoBERTa, ƒë·∫∑c bi·ªát tr√™n t·∫≠p d·ªØ li·ªáu ph·ª©c t·∫°p ho·∫∑c ƒëa ng√¥n ng·ªØ (nh∆∞ ti·∫øng Anh-Vi·ªát).\n",
    "- **Khi n√†o n√™n d√πng**: N·∫øu t√†i nguy√™n t√≠nh to√°n b·ªã gi·ªõi h·∫°n v√† task kh√¥ng qu√° ph·ª©c t·∫°p.\n",
    "\n",
    "#### **2. XLM-RoBERTa**:\n",
    "- **∆Øu ƒëi·ªÉm**: Hi·ªáu su·∫•t cao h∆°n mBERT trong h·∫ßu h·∫øt c√°c t√°c v·ª• ƒëa ng√¥n ng·ªØ. ƒê·∫∑c bi·ªát t·ªët cho ti·∫øng Anh v√† ti·∫øng Vi·ªát.\n",
    "- **Nh∆∞·ª£c ƒëi·ªÉm**: Y√™u c·∫ßu t√†i nguy√™n t√≠nh to√°n l·ªõn h∆°n, t·ªëc ƒë·ªô inference ch·∫≠m h∆°n m·ªôt ch√∫t.\n",
    "- **Khi n√†o n√™n d√πng**: N·∫øu ∆∞u ti√™n ƒë·ªô ch√≠nh x√°c cao h∆°n v√† t√†i nguy√™n kh√¥ng ph·∫£i v·∫•n ƒë·ªÅ l·ªõn.\n",
    "\n",
    "#### **3. ProphetNet**:\n",
    "- **∆Øu ƒëi·ªÉm**: T·ªëi ∆∞u cho b√†i to√°n sinh ng·ªØ c·∫£nh t∆∞∆°ng lai, nh∆∞ t√≥m t·∫Øt vƒÉn b·∫£n, tr·∫£ l·ªùi c√¢u h·ªèi.\n",
    "- **Nh∆∞·ª£c ƒëi·ªÉm**: Kh√¥ng ph√π h·ª£p v·ªõi c√°c t√°c v·ª• ph√¢n lo·∫°i. Kh√¥ng h·ªó tr·ª£ t·ªët ƒëa ng√¥n ng·ªØ.\n",
    "- **Khi n√†o n√™n d√πng**: N·∫øu b·∫°n l√†m b√†i to√°n text generation ho·∫∑c summarization, kh√¥ng ph·∫£i classification.\n",
    "\n",
    "---\n",
    "\n",
    "### **G·ª£i √Ω ch·ªçn m√¥ h√¨nh cho task c·ªßa b·∫°n**:\n",
    "1. **∆Øu ti√™n ch√≠nh x√°c**: D√πng **XLM-RoBERTa** (ho·∫∑c DistilXLM-RoBERTa n·∫øu c·∫ßn gi·∫£m k√≠ch th∆∞·ªõc).\n",
    "2. **∆Øu ti√™n t·ªëc ƒë·ªô v√† t√†i nguy√™n**: D√πng **mBERT**.\n",
    "3. **Kh√¥ng d√πng ProphetNet**: V√¨ kh√¥ng t·ªëi ∆∞u cho ph√¢n lo·∫°i.\n",
    "\n",
    "C·∫ßn th√™m h·ªó tr·ª£ g√¨, b·∫°n c√≥ th·ªÉ n√≥i r√µ h∆°n nh√©! üòä"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Test chung trên:\n",
    "```python\n",
    "input_file = \"/content/processed_data_example_v4_15000Data.xlsx\"\n",
    "output_file = \"evaluation_results.xlsx\"\n",
    "num_rows = 500  # Số lượng dòng muốn đánh giá\n",
    "```\n",
    "- https://wandb.ai/doanngoccuong_nh/bertIntentClassification/artifacts/model/best_model_epoch_30/v0/usage => 83.33%   (Train trên Bộ 10000 hay bộ 15000 data ko nhớ)\n",
    "- https://wandb.ai/doanngoccuong_nh/bertIntentClassification/artifacts/model/best_model_epoch_10/v0 (Train trên bộ 10000) => 86.67%\n",
    "- https://wandb.ai/doanngoccuong_nh/bertIntentClassification/artifacts/model/best_model_epoch_10/v0 (Train trên bộ 15000) => 90.00%\n",
    "- https://wandb.ai/doanngoccuong_nh/bertIntentClassification/artifacts/model/best_model_epoch_80/v0/usage  => 96.67% (Train trên bộ 15000 data)\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Chuyển sang bộ data mới toanh đánh giá cho chuẩn hơn: (50 cụm mới hoàn toàn)\n",
    "```\n",
    "600 dòng - 50 cụm từ * 12\n",
    "```\n",
    "- Acc: 68.49%\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[OVERFITTING Report]: Em gửi report phần model hiện tại ạ.\n",
    "\n",
    "\n",
    "Dataset: 15000 bộ: robot - user_answer - user_intent. \n",
    "Cách tạo: 500 cụm từ * 3 dạng bài * 12 Turn (1 conversation: robot - user_answer_intent) = 15000 dòng data.\n",
    "\n",
    "2. Model: BERT, 450MB,\n",
    "Accuracy trên 500 dòng data đã train: 90%\n",
    "Accuracy trên 5000 dòng data đã train: 86.67%\n",
    "Accuracy (đánh giá trên 600 dòng mới toanh) Acc: 46.67%\n",
    "\n",
    "3. Train: 100 epochs, so sánh các best_eval (epoch30, 80, ...)\n",
    "----\n",
    "Link: https://docs.google.com/spreadsheets/d/1yh_b0XCiyAgaqpeez9GO9jJnaDsiEdg3w6SgZ5U8-1g/edit?usp=sharing\n",
    "----\n",
    "\n",
    "-------\n",
    "Model Overfititng,\n",
    "Dự đoán nguyên nhân:\n",
    "\n",
    "1.  Overfitting do tập train quá ít đa dạng:\n",
    "- 15,000 dòng data từ 500 cụm từ (gốc) => mô hình \"học thuộc\" hơn là \"học cách tổng quát\".  \n",
    "- Trong khi đó bộ test được tạo từ 50 cụm mới. \n",
    "\n",
    "2. \n",
    "3. \n",
    "Hướng cải thiện:\n",
    "Sử dụng 1 model tốt hơn, có thể là: XLM-R (XLM-RoBERTa); Kết hợp PhoBERT + BERTweet\n",
    "Đa dạng các cụm tiếng anh hơn là chỉ 500 cụm gen tới 15000 bộ question-answer. \n",
    "\n",
    "====\n",
    "\n",
    "anh @cuongvc, anh @Đinh Hùng, anh @Minh Hoang Duc\n",
    "---\n",
    "a @Đinh Hùng ơi SOS Ạ.!!!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rò rỉ chỉ xảy ra nếu:\n",
    "\n",
    "- Tập validation bị sử dụng trực tiếp trong quá trình tối ưu hóa mô hình.\n",
    "- Hoặc bạn kết hợp train và validation mà không tách biệt đúng cách."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để kiểm tra xem **tập validation có bị sử dụng trực tiếp trong quá trình tối ưu hóa mô hình không**, cần xem xét kỹ từng phần trong đoạn code:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **Trong `TrainerCustom.compute_loss`**\n",
    "Phương thức `compute_loss` thực hiện các bước sau:\n",
    "- Lấy dữ liệu đầu vào (`inputs`) và tách nhãn (`labels`) nếu có.\n",
    "- Tính toán loss bằng cách so sánh dự đoán (`logits`) của mô hình với `labels` bằng `nn.CrossEntropyLoss`.\n",
    "\n",
    "**Quan trọng**:\n",
    "- `compute_loss` được gọi trong quá trình huấn luyện (`train`), và dữ liệu đầu vào cho nó được lấy từ `train_dataset`.\n",
    "- **Không có bất kỳ đoạn nào sử dụng `test_dataset` hoặc tập validation trong `compute_loss`**.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Trong `TrainerCustom.evaluate`**\n",
    "Phương thức `evaluate` chỉ được gọi sau khi hoàn thành một epoch hoặc tại các điểm đánh giá theo chiến lược (`eval_strategy=\"epoch\"`). Nó:\n",
    "- Sử dụng `test_dataset` để tính `eval_loss`.\n",
    "- **Không thực hiện cập nhật trọng số mô hình** khi tính `eval_loss`.\n",
    "\n",
    "Do đó, không có rò rỉ nào xảy ra ở đây.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Trong `TrainerCustom.train`**\n",
    "Phương thức `train` gọi `compute_loss` để tính toán loss cho từng batch và cập nhật trọng số mô hình. Dữ liệu đầu vào cho `compute_loss` đến từ `train_dataset`. \n",
    "\n",
    "- `train_dataset` được sử dụng để tối ưu hóa mô hình.\n",
    "- **Không có chỗ nào sử dụng `test_dataset` trong phương thức `train` hoặc quá trình tối ưu hóa**.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Sử dụng tập validation trong cập nhật trọng số**\n",
    "Để xác nhận rõ hơn, bạn có thể thêm các đoạn log kiểm tra trong `compute_loss` và `evaluate` để đảm bảo rằng dữ liệu từ `test_dataset` không bị sử dụng trong tối ưu hóa:\n",
    "\n",
    "#### Kiểm tra trong `compute_loss`:\n",
    "```python\n",
    "def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "    if inputs.get(\"dataset\") == \"test\":\n",
    "        print(\"WARNING: Validation data used in compute_loss!\")\n",
    "    ...\n",
    "```\n",
    "\n",
    "#### Kiểm tra trong `evaluate`:\n",
    "```python\n",
    "def evaluate(self, eval_dataset=None, ignore_keys=None, metric_key_prefix: str = \"eval\"):\n",
    "    print(f\"Evaluating with {metric_key_prefix}, dataset: {eval_dataset}\")\n",
    "    return super().evaluate(eval_dataset, ignore_keys, metric_key_prefix)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Cách xác định vấn đề rò rỉ:**\n",
    "Rò rỉ xảy ra nếu:\n",
    "1. **`test_dataset` bị sử dụng trong quá trình huấn luyện.** Điều này có thể xảy ra nếu `test_dataset` vô tình được đưa vào trong `train()` hoặc `compute_loss`.\n",
    "2. **`train_dataset` và `test_dataset` không được tách biệt đúng cách**. Ví dụ, nếu `train_dataset` và `test_dataset` có mẫu trùng nhau, điều đó dẫn đến rò rỉ.\n",
    "\n",
    "Bạn có thể thêm đoạn kiểm tra:\n",
    "```python\n",
    "# Kiểm tra xem train_dataset và test_dataset có trùng mẫu không\n",
    "train_ids = set(train_dataset[\"id\"])  # Nếu dataset có trường \"id\"\n",
    "test_ids = set(test_dataset[\"id\"])\n",
    "\n",
    "overlap = train_ids.intersection(test_ids)\n",
    "if len(overlap) > 0:\n",
    "    print(f\"WARNING: {len(overlap)} samples are shared between train and test datasets!\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 6. **Kết luận:**\n",
    "Dựa trên code bạn cung cấp:\n",
    "- **Tập validation không bị sử dụng trực tiếp trong tối ưu hóa mô hình**.\n",
    "- Đảm bảo rằng `train_dataset` và `test_dataset` được tách biệt đúng cách.\n",
    "\n",
    "Nếu bạn thấy tập validation bị sử dụng trong tối ưu hóa, hãy kiểm tra kỹ log hoặc quy trình xử lý dữ liệu ban đầu (`train_test_split` hoặc pipeline dữ liệu)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import wandb\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "class TrainerCustom(Trainer):\n",
    "    def __init__(self, *args, save_every_n_epochs=10, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        if torch.cuda.is_available():\n",
    "            print(f\"Trainer is running on GPU: {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n",
    "        else:\n",
    "            print(\"Trainer is running on CPU.\")\n",
    "\n",
    "        self.best_eval_loss = float(\"inf\")  # Giá trị loss tốt nhất ban đầu\n",
    "        self.save_every_n_epochs = save_every_n_epochs  # Tần suất lưu lên WandB\n",
    "        self.best_model_info = {\"epoch\": None, \"loss\": None}\n",
    "        self.last_saved_epoch = 0  # Epoch cuối cùng đã lưu Best Model và Last Model\n",
    "        self.executor = ThreadPoolExecutor(max_workers=3)  # Cho phép tối đa 2 luồng song song\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        \"\"\"\n",
    "        How the loss is computed by Trainer. By default, all models return the loss in the first element.\n",
    "\n",
    "        Subclass and override for custom behavior.\n",
    "        \"\"\"\n",
    "\n",
    "        # # Kiểm tra thiết bị của mô hình và dữ liệu\n",
    "        # print(\"Model device:\", next(model.parameters()).device)\n",
    "        # print(\"Input device:\", inputs[\"input_ids\"].device)\n",
    "        if \"labels\" in inputs:\n",
    "            labels = inputs.pop(\"labels\")\n",
    "        else:\n",
    "            labels = None\n",
    "\n",
    "        # Sử dụng nn.CrossEntropyLoss() thay vì nn.CrossEntropy\n",
    "        cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Chạy mô hình và nhận đầu ra (logits)\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        # Đảm bảo lấy logits từ outputs (mô hình trả về tuple, lấy phần tử đầu tiên là logits)\n",
    "        logits = outputs\n",
    "\n",
    "        if labels is None:\n",
    "            print(\"Labels are None during compute_loss.\")\n",
    "        if logits is None:\n",
    "            print(\"Logits are None during compute_loss.\")\n",
    "\n",
    "        # Tính toán loss\n",
    "        loss = cross_entropy_loss(logits, labels)\n",
    "\n",
    "        # Trả về loss và outputs nếu cần\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "    def async_save_model(self, model_dir, artifact_name, metadata=None):\n",
    "        \"\"\"\n",
    "        Lưu mô hình vào local và đồng bộ lên WandB trong luồng song song.\n",
    "        \"\"\"\n",
    "        def save():\n",
    "            start_time = time.time()\n",
    "            try:\n",
    "                # Xóa tất cả các thư mục tmp_best_model_ trước đó\n",
    "                for folder in os.listdir(\".\"):\n",
    "                    if folder.startswith(\"tmp_best_model_epoch_\") and folder != model_dir:\n",
    "                        shutil.rmtree(folder, ignore_errors=True)\n",
    "                        print(f\"Removed old temporary directory: {folder}\")\n",
    "\n",
    "                # Lưu mô hình vào thư mục tạm\n",
    "                self.save_model(model_dir)\n",
    "\n",
    "                # Đồng bộ lên WandB\n",
    "                artifact = wandb.Artifact(artifact_name, type=\"model\")\n",
    "                artifact.add_dir(model_dir)\n",
    "                if metadata:\n",
    "                    artifact.metadata = metadata\n",
    "                wandb.log_artifact(artifact)\n",
    "            except Exception as e:\n",
    "                print(f\"Error during saving or syncing model {artifact_name}: {e}\")\n",
    "            finally:\n",
    "                # Xóa thư mục tạm hiện tại sau khi đồng bộ\n",
    "                try:\n",
    "                    shutil.rmtree(model_dir, ignore_errors=True)\n",
    "                    print(f\"Successfully removed temporary directory: {model_dir}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error removing temporary directory {model_dir}: {e}\")\n",
    "\n",
    "            elapsed_time = time.time() - start_time\n",
    "            print(f\"Model saved and uploaded to WandB: {artifact_name} in {elapsed_time:.2f} seconds\")\n",
    "\n",
    "        self.executor.submit(save)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def evaluate(self, eval_dataset=None, ignore_keys=None, metric_key_prefix: str = \"eval\"):\n",
    "        metrics = super().evaluate(eval_dataset, ignore_keys, metric_key_prefix)\n",
    "        eval_loss = metrics.get(\"eval_loss\")\n",
    "\n",
    "        # Cập nhật Best Model nếu eval_loss giảm\n",
    "        # Lưu Best Model ngay khi eval_loss giảm (local).\n",
    "        # Đồng bộ wandb ngay\n",
    "\n",
    "        if eval_loss is not None and eval_loss < self.best_eval_loss:\n",
    "            print(f\"New best eval_loss: {eval_loss}\")\n",
    "            self.best_eval_loss = eval_loss\n",
    "            self.best_model_info = {\"epoch\": self.state.epoch, \"loss\": eval_loss}\n",
    "\n",
    "            # Log thông tin Best Model lên WandB\n",
    "            wandb.log({\n",
    "                \"best_eval_loss\": self.best_eval_loss,\n",
    "                \"best_model_epoch\": self.best_model_info.get(\"epoch\", -1)\n",
    "            })\n",
    "\n",
    "            # Lưu Best Model vào thư mục tạm (local)\n",
    "            best_model_dir = f\"./tmp_best_model_epoch_{int(self.state.epoch)}\"\n",
    "            self.save_model(best_model_dir)\n",
    "\n",
    "            # Đồng bộ lên WandB ngay\n",
    "            artifact_name = f\"best_model_epoch_{int(self.state.epoch)}\"\n",
    "            self.async_save_model(best_model_dir, artifact_name, self.best_model_info)\n",
    "\n",
    "        return metrics\n",
    "\n",
    "    # def save_last_model(self):\n",
    "    #     \"\"\"\n",
    "    #     Lưu Last Model lên WandB sau mỗi N epochs.\n",
    "    #     \"\"\"\n",
    "    #     if int(self.state.epoch) % self.save_every_n_epochs == 0 and int(self.state.epoch) != self.last_saved_epoch:\n",
    "    #         print(f\"Saving Last Model at epoch {self.state.epoch} to WandB...\")\n",
    "    #         last_model_dir = f\"./tmp_last_model_epoch_{int(self.state.epoch)}\"\n",
    "    #         artifact_name = f\"last_model_epoch_{int(self.state.epoch)}\"\n",
    "    #         self.async_save_model(last_model_dir, artifact_name)\n",
    "\n",
    "    #         # Log thông tin Last Model lên WandB\n",
    "    #         wandb.log({\n",
    "    #             \"last_model_epoch\": self.state.epoch\n",
    "    #         })\n",
    "\n",
    "    #         # Cập nhật epoch cuối cùng đã lưu\n",
    "    #         self.last_saved_epoch = int(self.state.epoch)\n",
    "\n",
    "    def save_last_model(self):\n",
    "        \"\"\"\n",
    "        Lưu Last Model (bao gồm trạng thái optimizer, scheduler) lên WandB sau mỗi N epochs.\n",
    "        \"\"\"\n",
    "        if int(self.state.epoch) % self.save_every_n_epochs == 0 and int(self.state.epoch) != self.last_saved_epoch:\n",
    "            print(f\"Saving Last Model at epoch {self.state.epoch} to WandB...\")\n",
    "\n",
    "            # Thư mục tạm lưu checkpoint\n",
    "            last_model_dir = f\"./tmp_last_model_epoch_{int(self.state.epoch)}\"\n",
    "            os.makedirs(last_model_dir, exist_ok=True)\n",
    "\n",
    "            # Lưu đầy đủ trạng thái mô hình (checkpoint)\n",
    "            self.save_model(last_model_dir)\n",
    "\n",
    "            # Đường dẫn tệp trainer_state.json\n",
    "            trainer_state_path = os.path.join(last_model_dir, \"trainer_state.json\")\n",
    "            self.state.save_to_json(trainer_state_path)  # Lưu trạng thái trainer\n",
    "\n",
    "            # Đồng bộ checkpoint lên WandB\n",
    "            artifact_name = f\"last_model_epoch_{int(self.state.epoch)}\"\n",
    "            metadata = {\n",
    "                \"epoch\": int(self.state.epoch),\n",
    "                \"last_eval_loss\": self.state.best_metric if hasattr(self.state, \"best_metric\") else \"N/A\",\n",
    "            }\n",
    "            self.async_save_model(last_model_dir, artifact_name, metadata)\n",
    "\n",
    "            # Cập nhật epoch cuối cùng đã lưu\n",
    "            self.last_saved_epoch = int(self.state.epoch)\n",
    "\n",
    "\n",
    "    def train(self, *args, **kwargs):\n",
    "        result = super().train(*args, **kwargs)\n",
    "\n",
    "        # Sau mỗi epoch, lưu Last Model lên WandB\n",
    "        self.save_last_model()\n",
    "        # Chờ tất cả các luồng lưu hoàn thành trước khi kết thúc\n",
    "        self.executor.shutdown(wait=True)\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "# Bước 6: Cài đặt tham số huấn luyện\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./result__s\",          # Thư mục lưu kết quả\n",
    "    eval_strategy=\"epoch\",    # Đánh giá sau mỗi epoch\n",
    "    learning_rate=2e-4,\n",
    "    per_device_train_batch_size=128,\n",
    "    per_device_eval_batch_size=128,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=1,  # Ghi logs mỗi 500 bước huấn luyện\n",
    "    save_strategy=\"no\",          # Lưu trọng số sau mỗi epoch\n",
    "    save_total_limit=3,\n",
    "    label_names = [\"labels\"],\n",
    "    report_to=\"wandb\",\n",
    "    run_name=\"bert_run_3\"\n",
    ")\n",
    "\n",
    "\n",
    "import wandb\n",
    "\n",
    "# Khởi tạo wandb\n",
    "wandb.init(\n",
    "    project=\"bertIntentClassification\",  # Tên dự án\n",
    "    name=\"bert_10000Data_1epoch\",                     # Tên phiên chạy\n",
    "    config={\"gpu\": torch.cuda.get_device_name(torch.cuda.current_device()) if torch.cuda.is_available() else \"CPU\"}\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Trainer is running on GPU: {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n",
    "else:\n",
    "    print(\"Trainer is running on CPU.\")\n",
    "\n",
    "trainer = TrainerCustom(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    data_collator=collate_fn,\n",
    "    save_every_n_epochs=3  # Lưu Best Model và Last Model mỗi 10 epochs\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "wandb.finish()\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

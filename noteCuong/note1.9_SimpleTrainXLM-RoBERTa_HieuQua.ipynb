{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import psutil\n",
    "import os\n",
    "import GPUtil\n",
    "from threading import Thread\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Kiểm tra CUDA\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA device name:\", torch.cuda.get_device_name(0))\n",
    "    print(\"CUDA device count:\", torch.cuda.device_count())\n",
    "\n",
    "# 1. Chuẩn bị dữ liệu\n",
    "def prepare_dataset(file_path, text_columns, label_column, tokenizer, max_seq_length):\n",
    "    \"\"\"\n",
    "    Chuẩn bị dữ liệu từ file Excel và chia thành train/valid.\n",
    "    \"\"\"\n",
    "    # Đọc dữ liệu\n",
    "    df = pd.read_excel(file_path)\n",
    "    \n",
    "    # Ghép văn bản\n",
    "    def combine_text(row):\n",
    "        question = row[text_columns[0]].strip().lower()\n",
    "        answer = row[text_columns[1]].strip().lower() if pd.notna(row[text_columns[1]]) else \"\"\n",
    "        return f\"question: {question}. answer: {answer}\"\n",
    "\n",
    "    df[\"input_text\"] = df.apply(combine_text, axis=1)\n",
    "\n",
    "    # Chuyển đổi nhãn thành số\n",
    "    unique_labels = sorted(df[label_column].unique())\n",
    "    label2id = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "    df[\"label\"] = df[label_column].map(label2id)\n",
    "\n",
    "    # Chia train/valid\n",
    "    train_df, valid_df = train_test_split(df, test_size=0.25, random_state=42, stratify=df[\"label\"])\n",
    "    print(f\"Training samples: {len(train_df)}, Validation samples: {len(valid_df)}\")\n",
    "\n",
    "    # Function để tokenize DataFrame\n",
    "    def tokenize_df(df):\n",
    "        tokenized_data = tokenizer(\n",
    "            list(df[\"input_text\"]),\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=max_seq_length\n",
    "        )\n",
    "        tokenized_data[\"labels\"] = list(df[\"label\"])\n",
    "        return Dataset.from_dict(tokenized_data)\n",
    "\n",
    "    # Tokenize cả train và valid\n",
    "    train_dataset = tokenize_df(train_df)\n",
    "    valid_dataset = tokenize_df(valid_df)\n",
    "\n",
    "    return train_dataset, valid_dataset, label2id\n",
    "\n",
    "# Cấu hình\n",
    "file_path = \"processed_data_example_v5_15000Data_addNewDang123.xlsx\"  # Đường dẫn file dữ liệu\n",
    "text_columns = [\"robot\", \"user_answer\"]\n",
    "label_column = \"user_intent\"\n",
    "max_seq_length = 128\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "\n",
    "# Chuẩn bị dataset\n",
    "train_dataset, valid_dataset, label2id = prepare_dataset(file_path, text_columns, label_column, tokenizer, max_seq_length)\n",
    "print(f\"Label mapping: {label2id}\")\n",
    "\n",
    "# 2. Huấn luyện mô hình \n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"xlm-roberta-base\", num_labels=len(label2id))\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Hàm tính toán các metric.\"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    preds = predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    return {\"accuracy\": acc, \"f1\": f1}\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=100,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=5,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,  # Thay bằng valid_dataset thay vì dùng train_dataset\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "def monitor_resources():\n",
    "    \"\"\"Hàm theo dõi tài nguyên hệ thống\"\"\"\n",
    "    while True:\n",
    "        # RAM Usage\n",
    "        ram = psutil.virtual_memory()\n",
    "        print(f\"\\nRAM Usage: {ram.percent}%\")\n",
    "        print(f\"Used RAM: {ram.used/1024/1024/1024:.2f}GB\")\n",
    "        print(f\"Available RAM: {ram.available/1024/1024/1024:.2f}GB\")\n",
    "        \n",
    "        # GPU Usage (nếu có CUDA)\n",
    "        if torch.cuda.is_available():\n",
    "            gpus = GPUtil.getGPUs()\n",
    "            for gpu in gpus:\n",
    "                print(f\"GPU {gpu.id} Memory Usage: {gpu.memoryUsed}MB/{gpu.memoryTotal}MB ({gpu.memoryUtil*100:.1f}%)\")\n",
    "        \n",
    "        time.sleep(30)  # Cập nhật mỗi 30 giây\n",
    "\n",
    "# Khởi động thread monitor\n",
    "monitor_thread = Thread(target=monitor_resources, daemon=True)\n",
    "monitor_thread.start()\n",
    "\n",
    "# Thêm vào trước khi bắt đầu training\n",
    "print(\"Starting training...\")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# 3. Đánh giá trên tập test sau khi training xong dựa vào last model\n",
    "def evaluate_model(test_file_path):\n",
    "    \"\"\"Đánh giá mô hình trên tập test, với last model đã huấn luyện.\"\"\"\n",
    "    test_dataset, _, _ = prepare_dataset(test_file_path, text_columns, label_column, tokenizer, max_seq_length)\n",
    "    results = trainer.predict(test_dataset)\n",
    "\n",
    "    print(\"Metrics:\", results.metrics)\n",
    "\n",
    "    # Xử lý nhãn dự đoán\n",
    "    predictions = results.predictions.argmax(axis=1)\n",
    "    test_dataset = test_dataset.to_pandas()\n",
    "    test_dataset[\"predicted_label\"] = predictions\n",
    "    test_dataset[\"predicted_label_name\"] = test_dataset[\"predicted_label\"].map({v: k for k, v in label2id.items()})\n",
    "\n",
    "    # Lưu bản gốc ra file\n",
    "    original_df = pd.read_excel(test_file_path)\n",
    "    original_df[\"predicted_label\"] = test_dataset[\"predicted_label\"]\n",
    "    original_df[\"predicted_label_name\"] = test_dataset[\"predicted_label_name\"]\n",
    "\n",
    "    # Lưu kết quả ra file\n",
    "    original_df.to_excel(\"eval_results_test2_1000processedDang123new.xlsx\", index=False)\n",
    "    print(\"Test results saved to eval_results_test2_1000processedDang123new.xlsx\")\n",
    "\n",
    "# Đường dẫn tập test\n",
    "test_file_path = \"test2_1000processedDang123new.xlsx\"\n",
    "evaluate_model(test_file_path, model_path)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trong đoạn mã của bạn, tên của model sau khi huấn luyện sẽ được lưu tự động bởi `Trainer` vào thư mục được cấu hình bởi tham số `output_dir` trong `TrainingArguments`. Cụ thể, model sẽ được lưu trong thư mục `\"./results\"` theo các checkpoint tương ứng với mỗi epoch, ví dụ:\n",
    "\n",
    "```\n",
    "./results/checkpoint-<step>\n",
    "```\n",
    "\n",
    "Trong đó `<step>` là số bước huấn luyện đã hoàn thành (step count).\n",
    "\n",
    "Ngoài ra, nếu bạn bật tham số `load_best_model_at_end=True`, Trainer sẽ tự động sử dụng checkpoint có kết quả tốt nhất (dựa trên `metric_for_best_model`, trong trường hợp này là `\"accuracy\"`). Checkpoint tốt nhất này sẽ được tải lên khi huấn luyện kết thúc và có thể được lưu hoặc sử dụng cho các bước tiếp theo.\n",
    "\n",
    "Nếu bạn muốn lưu model cuối cùng hoặc model tốt nhất thành một thư mục cụ thể, bạn có thể sử dụng:\n",
    "\n",
    "```python\n",
    "trainer.save_model(\"path/to/save/final_model\")\n",
    "```\n",
    "\n",
    "Ví dụ, nếu muốn lưu model vào thư mục `\"final_model\"`:\n",
    "\n",
    "```python\n",
    "trainer.save_model(\"./final_model\")\n",
    "```\n",
    "\n",
    "Sau đó, model được lưu sẽ chứa các file như:\n",
    "- `config.json`\n",
    "- `pytorch_model.bin`\n",
    "- `tokenizer_config.json`\n",
    "- `vocab.json` hoặc `merges.txt` (tuỳ thuộc vào tokenizer).\n",
    "\n",
    "### Gợi ý:\n",
    "- Nếu bạn chỉ cần sử dụng model tốt nhất, bạn nên đảm bảo đã bật `load_best_model_at_end=True` và kiểm tra thư mục `./results` để tìm checkpoint tốt nhất.\n",
    "- Để rõ ràng, bạn có thể in ra checkpoint tốt nhất bằng cách:\n",
    "\n",
    "```python\n",
    "print(\"Best model path:\", trainer.state.best_model_checkpoint)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

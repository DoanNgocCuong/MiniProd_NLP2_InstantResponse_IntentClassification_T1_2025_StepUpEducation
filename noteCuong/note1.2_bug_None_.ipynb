{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# Bước 7: Tạo Trainer\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=1,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=1,  # Ghi log mỗi bước\n",
    ")\n",
    "\n",
    "trainer = TrainerCustom(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    data_collator=collate_fn,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "\n",
    "# Bước 8: Huấn luyện\n",
    "trainer.train()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lỗi \n",
    "```\n",
    "Inputs being passed to tokenizer: [None, None, None, None, None, None, None, None]\n",
    "---------------------------------------------------------------------------\n",
    "AssertionError                            Traceback (most recent call last)\n",
    "<ipython-input-94-c1d51e013c93> in <cell line: 21>()\n",
    "     19 )\n",
    "     20 \n",
    "---> 21 trainer.train()\n",
    "     22 \n",
    "     23 # Đánh giá trên tập kiểm tra\n",
    "\n",
    "7 frames\n",
    "<ipython-input-93-31b340d4e174> in collate_fn(features)\n",
    "      7 \n",
    "      8     # Đảm bảo tất cả các phần tử trong inputs là chuỗi\n",
    "----> 9     assert all(isinstance(text, str) for text in inputs), \"Some inputs are not strings!\"\n",
    "     10 \n",
    "     11     labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "AssertionError: Some inputs are not strings!\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check  mọi thứ bình thường ko biết lỗi ở đâu: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python \n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Kiểm tra DataLoader để đảm bảo không có None trong các batch\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=2,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "for batch in train_loader:\n",
    "    print(batch)\n",
    "    break  # In thử một batch đầu tiên\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "Inputs being passed to tokenizer: ['Tôi không chắc, hãy để tôi kiểm tra lại.', 'Bạn có thể nhắc lại không?']\n",
    "{'input_ids': tensor([[  101,  2000,  2072,  1047, 19991, 15775,  2278,  1010, 10974,  1102,\n",
    "          2063,  2000,  2072, 11382,  6633, 19817,  2050, 21110,  1012,   102],\n",
    "        [  101,  7221,  2522,  1996, 18699,  6305, 21110,  1047, 19991,  1029,\n",
    "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'labels': tensor([2, 0])}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python \n",
    "# Lấy batch từ DataLoader\n",
    "for batch in train_loader:\n",
    "    input_ids = batch[\"input_ids\"]\n",
    "    attention_mask = batch[\"attention_mask\"]\n",
    "    labels = batch[\"labels\"]\n",
    "    break\n",
    "\n",
    "# Chuyển batch sang thiết bị (CPU/GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_ids = input_ids.to(device)\n",
    "attention_mask = attention_mask.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "# Chạy qua model\n",
    "model = model.to(device)\n",
    "outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "print(\"Model outputs:\", outputs)\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "Inputs being passed to tokenizer: ['Tôi không chắc, hãy để tôi kiểm tra lại.', 'Bạn có thể nhắc lại không?']\n",
    "Model outputs: tensor([[ 0.1334, -0.1960, -0.1488, -0.3732, -0.3232],\n",
    "        [ 0.3185,  0.1669, -0.2354, -0.4047, -0.3181]],\n",
    "       grad_fn=<AddmmBackward0>)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "===== Một số mẫu trong DataFrame =====\n",
    "                                       text           intent\n",
    "0     Vâng, tôi muốn cho bạn xem bức tranh.           Đồng ý\n",
    "1                    Không, tôi không muốn.          Từ chối\n",
    "2                           Tôi không biết.  Không chắc chắn\n",
    "3  Xin lỗi, tôi không hiểu bạn đang nói gì.         Fallback\n",
    "4             Được rồi, để tôi cho bạn xem.           Đồng ý\n",
    "\n",
    "===== Kiểm Tra Giá Trị Không Hợp Lệ Trong Cột 'text' =====\n",
    "Số giá trị None: 0\n",
    "Số giá trị rỗng: 0\n",
    "===== Features của Dataset =====\n",
    "{'text': Value(dtype='string', id=None), 'label': Value(dtype='string', id=None)}\n",
    "===== Một số mẫu trong Dataset =====\n",
    "{'text': 'Vâng, tôi muốn cho bạn xem bức tranh.', 'label': 'Đồng ý'}\n",
    "{'text': 'Không, tôi không muốn.', 'label': 'Từ chối'}\n",
    "{'text': 'Tôi không biết.', 'label': 'Không chắc chắn'}\n",
    "{'text': 'Xin lỗi, tôi không hiểu bạn đang nói gì.', 'label': 'Fallback'}\n",
    "{'text': 'Được rồi, để tôi cho bạn xem.', 'label': 'Đồng ý'}\n",
    "\n",
    "===== Invalid Samples After Preprocessing =====\n",
    "[]\n",
    "Label mapping: {'Fallback': 0, 'Im lặng': 1, 'Không chắc chắn': 2, 'Từ chối': 3, 'Đồng ý': 4}\n",
    "Số lượng lớp (num_classes): 5\n",
    "Map: 100%\n",
    " 21/21 [00:00<00:00, 858.58 examples/s]\n",
    "Map: 100%\n",
    " 6/6 [00:00<00:00, 267.12 examples/s]\n",
    "===== Một số mẫu trong Train Dataset sau khi chuyển đổi nhãn =====\n",
    "{'text': 'Tôi không chắc, hãy để tôi kiểm tra lại.', 'label': 2}\n",
    "{'text': 'Bạn có thể nhắc lại không?', 'label': 0}\n",
    "{'text': 'Hoàn toàn chính xác, để tôi làm.', 'label': 4}\n",
    "{'text': 'Không, điều đó không đúng.', 'label': 3}\n",
    "{'text': 'Chắc chắn rồi, để tôi làm.', 'label': 4}\n",
    "===== Một số mẫu trong Test Dataset sau khi chuyển đổi nhãn =====\n",
    "{'text': 'Tôi chưa hiểu rõ câu hỏi của bạn.', 'label': 0}\n",
    "{'text': 'Không có gì để nói cả.', 'label': 1}\n",
    "{'text': 'Để tôi xem xét thêm.', 'label': 2}\n",
    "{'text': 'Tôi chưa quyết định.', 'label': 2}\n",
    "{'text': 'Không, tôi không đồng ý.', 'label': 3}\n",
    "tokenizer_config.json: 100%\n",
    " 48.0/48.0 [00:00<00:00, 3.77kB/s]\n",
    "config.json: 100%\n",
    " 570/570 [00:00<00:00, 46.5kB/s]\n",
    "vocab.txt: 100%\n",
    " 232k/232k [00:00<00:00, 6.26MB/s]\n",
    "tokenizer.json: 100%\n",
    " 466k/466k [00:00<00:00, 7.35MB/s]\n",
    "\n",
    "===== Model Info =====\n",
    "BERTIntentClassification(\n",
    "  (bert): BertModel(\n",
    "    (embeddings): BertEmbeddings(\n",
    "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
    "      (position_embeddings): Embedding(512, 768)\n",
    "      (token_type_embeddings): Embedding(2, 768)\n",
    "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "      (dropout): Dropout(p=0.1, inplace=False)\n",
    "    )\n",
    "    (encoder): BertEncoder(\n",
    "      (layer): ModuleList(\n",
    "        (0-11): 12 x BertLayer(\n",
    "          (attention): BertAttention(\n",
    "            (self): BertSdpaSelfAttention(\n",
    "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
    "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
    "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
    "              (dropout): Dropout(p=0.1, inplace=False)\n",
    "            )\n",
    "            (output): BertSelfOutput(\n",
    "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
    "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "              (dropout): Dropout(p=0.1, inplace=False)\n",
    "            )\n",
    "          )\n",
    "          (intermediate): BertIntermediate(\n",
    "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
    "            (intermediate_act_fn): GELUActivation()\n",
    "          )\n",
    "          (output): BertOutput(\n",
    "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
    "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
    "            (dropout): Dropout(p=0.1, inplace=False)\n",
    "          )\n",
    "        )\n",
    "      )\n",
    "    )\n",
    "    (pooler): BertPooler(\n",
    "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
    "      (activation): Tanh()\n",
    "    )\n",
    "  )\n",
    "  (ffnn): Sequential(\n",
    "    (0): Linear(in_features=768, out_features=768, bias=True)\n",
    "    (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
    "    (2): ReLU()\n",
    "    (3): Dropout(p=0.1, inplace=False)\n",
    "    (4): Linear(in_features=768, out_features=5, bias=True)\n",
    "  )\n",
    ")\n",
    "Số lượng lớp (num_classes): 5\n",
    "\n",
    "===== Tokenizer Output =====\n",
    "Input IDs: tensor([[  101,  8418,  2078, 22455,  1010,  7221,  1047, 14490,  1047, 19991,\n",
    "          1029,   102]])\n",
    "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n",
    "\n",
    "===== Forward Pass Output =====\n",
    "Logits shape: torch.Size([1, 5])\n",
    "Logits: tensor([[ 0.3990,  0.3353, -0.5161, -0.2652, -0.4595]])\n",
    "Probabilities: tensor([[0.3051, 0.2863, 0.1222, 0.1570, 0.1293]])\n",
    "Predicted class: 0\n",
    "Loss: 2.0455498695373535\n",
    "<ipython-input-98-10abfcead99b>:254: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `TrainerCustom.__init__`. Use `processing_class` instead.\n",
    "  trainer = TrainerCustom(\n",
    "Sample with invalid text encountered: {'label': 2}\n",
    "Sample with invalid text encountered: {'label': 4}\n",
    "Sample with invalid text encountered: {'label': 4}\n",
    "Sample with invalid text encountered: {'label': 0}\n",
    "Sample with invalid text encountered: {'label': 0}\n",
    "Sample with invalid text encountered: {'label': 2}\n",
    "Sample with invalid text encountered: {'label': 4}\n",
    "Sample with invalid text encountered: {'label': 1}\n",
    "Inputs being passed to tokenizer: ['EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT']\n",
    "Sample with invalid text encountered: {'label': 4}\n",
    "Sample with invalid text encountered: {'label': 1}\n",
    "Sample with invalid text encountered: {'label': 4}\n",
    "Sample with invalid text encountered: {'label': 2}\n",
    "Sample with invalid text encountered: {'label': 1}\n",
    "Sample with invalid text encountered: {'label': 0}\n",
    "Sample with invalid text encountered: {'label': 0}\n",
    "Sample with invalid text encountered: {'label': 3}\n",
    "Inputs being passed to tokenizer: ['EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT']\n",
    " [9/9 00:17, Epoch 3/3]\n",
    "Epoch\tTraining Loss\tValidation Loss\n",
    "1\tNo log\tNo log\n",
    "2\tNo log\tNo log\n",
    "3\tNo log\tNo log\n",
    "Sample with invalid text encountered: {'label': 0}\n",
    "Sample with invalid text encountered: {'label': 2}\n",
    "Sample with invalid text encountered: {'label': 3}\n",
    "Sample with invalid text encountered: {'label': 3}\n",
    "Sample with invalid text encountered: {'label': 4}\n",
    "Inputs being passed to tokenizer: ['EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT']\n",
    "Sample with invalid text encountered: {'label': 0}\n",
    "Sample with invalid text encountered: {'label': 1}\n",
    "Sample with invalid text encountered: {'label': 2}\n",
    "Sample with invalid text encountered: {'label': 2}\n",
    "Sample with invalid text encountered: {'label': 3}\n",
    "Sample with invalid text encountered: {'label': 3}\n",
    "Inputs being passed to tokenizer: ['EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT']\n",
    "Sample with invalid text encountered: {'label': 0}\n",
    "Sample with invalid text encountered: {'label': 3}\n",
    "Sample with invalid text encountered: {'label': 4}\n",
    "Sample with invalid text encountered: {'label': 4}\n",
    "Sample with invalid text encountered: {'label': 0}\n",
    "Sample with invalid text encountered: {'label': 2}\n",
    "Sample with invalid text encountered: {'label': 4}\n",
    "Sample with invalid text encountered: {'label': 2}\n",
    "Inputs being passed to tokenizer: ['EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT']\n",
    "Sample with invalid text encountered: {'label': 1}\n",
    "Sample with invalid text encountered: {'label': 3}\n",
    "Sample with invalid text encountered: {'label': 2}\n",
    "Sample with invalid text encountered: {'label': 0}\n",
    "Sample with invalid text encountered: {'label': 3}\n",
    "Sample with invalid text encountered: {'label': 1}\n",
    "Sample with invalid text encountered: {'label': 1}\n",
    "Sample with invalid text encountered: {'label': 4}\n",
    "Inputs being passed to tokenizer: ['EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT']\n",
    "Sample with invalid text encountered: {'label': 4}\n",
    "Sample with invalid text encountered: {'label': 4}\n",
    "Sample with invalid text encountered: {'label': 0}\n",
    "Sample with invalid text encountered: {'label': 0}\n",
    "Sample with invalid text encountered: {'label': 2}\n",
    "Inputs being passed to tokenizer: ['EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT']\n",
    "Sample with invalid text encountered: {'label': 0}\n",
    "Sample with invalid text encountered: {'label': 1}\n",
    "Sample with invalid text encountered: {'label': 2}\n",
    "Sample with invalid text encountered: {'label': 2}\n",
    "Sample with invalid text encountered: {'label': 3}\n",
    "Sample with invalid text encountered: {'label': 3}\n",
    "Inputs being passed to tokenizer: ['EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT']\n",
    "Sample with invalid text encountered: {'label': 4}\n",
    "Sample with invalid text encountered: {'label': 4}\n",
    "Sample with invalid text encountered: {'label': 1}\n",
    "Sample with invalid text encountered: {'label': 2}\n",
    "Sample with invalid text encountered: {'label': 3}\n",
    "Sample with invalid text encountered: {'label': 4}\n",
    "Sample with invalid text encountered: {'label': 4}\n",
    "Sample with invalid text encountered: {'label': 3}\n",
    "Inputs being passed to tokenizer: ['EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT']\n",
    "Sample with invalid text encountered: {'label': 2}\n",
    "Sample with invalid text encountered: {'label': 1}\n",
    "Sample with invalid text encountered: {'label': 1}\n",
    "Sample with invalid text encountered: {'label': 0}\n",
    "Sample with invalid text encountered: {'label': 3}\n",
    "Sample with invalid text encountered: {'label': 0}\n",
    "Sample with invalid text encountered: {'label': 2}\n",
    "Sample with invalid text encountered: {'label': 4}\n",
    "Inputs being passed to tokenizer: ['EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT']\n",
    "Sample with invalid text encountered: {'label': 0}\n",
    "Sample with invalid text encountered: {'label': 4}\n",
    "Sample with invalid text encountered: {'label': 0}\n",
    "Sample with invalid text encountered: {'label': 2}\n",
    "Sample with invalid text encountered: {'label': 0}\n",
    "Inputs being passed to tokenizer: ['EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT']\n",
    "Sample with invalid text encountered: {'label': 0}\n",
    "Sample with invalid text encountered: {'label': 1}\n",
    "Sample with invalid text encountered: {'label': 2}\n",
    "Sample with invalid text encountered: {'label': 2}\n",
    "Sample with invalid text encountered: {'label': 3}\n",
    "Sample with invalid text encountered: {'label': 3}\n",
    "Inputs being passed to tokenizer: ['EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT']\n",
    "Sample with invalid text encountered: {'label': 0}\n",
    "Sample with invalid text encountered: {'label': 1}\n",
    "Sample with invalid text encountered: {'label': 2}\n",
    "Sample with invalid text encountered: {'label': 2}\n",
    "Sample with invalid text encountered: {'label': 3}\n",
    "Sample with invalid text encountered: {'label': 3}\n",
    "Inputs being passed to tokenizer: ['EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT', 'EMPTY_TEXT']\n",
    " [1/1 : < :]\n",
    "{'eval_runtime': 0.1329,\n",
    " 'eval_samples_per_second': 45.15,\n",
    " 'eval_steps_per_second': 7.525,\n",
    " 'epoch': 3.0}\n",
    "1\n",
    "Beta\n",
    "0 / 0\n",
    "used queries\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

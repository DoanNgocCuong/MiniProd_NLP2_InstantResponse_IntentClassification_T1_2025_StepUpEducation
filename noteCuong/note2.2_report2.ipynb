{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report FAST RESPONSE INTENTION. \n",
    "Hiệu suất tổng thể: \n",
    "| Model           | Bộ test 1 | Bộ test 2 |\n",
    "|------------------|-----------|-----------|\n",
    "| Bert            | 46.67%    | -         |\n",
    "| XLM-RoBERTa     | 79.1%     | 63.31%    |\n",
    "\n",
    "2. Đóng API: \n",
    "```bash\n",
    "curl --location 'http://103.253.20.13:25041/predict' \\\n",
    "--header 'Content-Type: application/json' \\\n",
    "--data '{\"robot\": \"Cậu có thể nói về gia đình cậu không? Like, who do you live with?\", \"user_answer\": \"Tớ sống với mẹ và ba, nhưng không có gì đặc biệt.\"}'\n",
    "```\n",
    "\n",
    "3. DATASET: \n",
    "Gen bổ sung 3 dạng 1, 2, 3 new Data (5000 dòng * 3 dạng) - trên tổng số 6 dạng. \n",
    "\n",
    "```\n",
    "Số lượng chủ đề bao phủ: \n",
    "500 cụm từ với 100 chủ đề, mỗi chủ đề 5 cụm\n",
    "```\n",
    "\n",
    "```\n",
    "6 dạng Conversation: \n",
    "1. Có sẵn từ, câu và present với user. Ví dụ: Từ con gà tiếng anh là Chicken. Cùng nhắc lại theo mình nhé or Cậu biết từ đánh răng tiếng anh là gì không. user trả lời brush my teeth.  \n",
    "2. Lấy thông tin từ user và present tiếng Anh. Ví dụ: Cậu thích ăn món gì, tớ thích ăn mì. Oh mì trong tiếng anh là noodle, nhắc lại theo tớ nhé noodle.    \n",
    "3. Có tình huống có sẵn để user phản xạ. Ví dụ: Cậu muốn mượn bạn cậu 1 quyển sách cậu nói thế nào? hoặc mẹ cậu đi làm về nhà và cậu chào mẹ. Chào mẹ trong tiếng anh là gì nhỉ \n",
    "4. Hỏi về các thông tin user có. Bây giờ tớ sẽ hỏi thông tin về gia đình cậu nhé. how many people are there in your house? Trả lời tớ bằng tiếng anh nhé    \n",
    "5. Đưa ra 1 đoạn cho user nhắc lại. Hôm nay chúng mình đã học được 3 câu, hãy nhắc lại theo tớ nhé. I wake up, i brush my teeth, i eat breakfast    \n",
    "6. Hỏi để user kể 1 đoạn. Ví dụ: Cậu hãy kể về 1 buối sáng của cậu bằng Tiếng Anh cho tớ nghe nhé   \n",
    "```\n",
    "\n",
    "=> Data: 500 cụm * 12 dòng data * 6 dạng = 30.000 dòng\n",
    "\n",
    "```\n",
    "- Vấn đề trong quá trình Prompt gen data: \n",
    "Các vấn đề thường gặp: \n",
    "1. Là conversation hợp lý không? => Đã thêm Conversation example ROBOT-USER\n",
    "Vấn đề là: Các nhãn hợp lý ko.  Có thể cần thêm ví dụ hoặc mô tả. \n",
    "2. Khi conversation hợp lý thì các nhãn nó tự gán có hợp lý không? -> - Thêm ví dụ để đảm bảo là các NHÃN ĐÚNG hơn. + thêm 'why_classification'\n",
    "Vấn đề: các câu robot - user_answer lại bị quá khớp với VÍ DỤ. \n",
    "3. Số lượng các nhãn thế nào -> 'turn'\n",
    "4. Số lượng ví dụ -> Tăng thêm VÍ DỤ cho từng nhãn\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Model\n",
    "\n",
    "Dưới đây là bảng so sánh các mô hình phổ biến cho bài toán **Sequence Classification**, tập trung vào những yếu tố như kích thước, tốc độ, hiệu suất, và các trường hợp sử dụng:\n",
    "\n",
    "| **Mô hình**          | **Số tham số** | **Kích thước (MB)** | **Ngôn ngữ hỗ trợ**       | **Ưu điểm**                                                                 | **Nhược điểm**                                                                                 | **Ứng dụng phổ biến**                                           |\n",
    "|-----------------------|----------------|----------------------|---------------------------|-----------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------|----------------------------------------------------------------|\n",
    "| **BERT**             | ~110M         | ~450                | Tiếng Anh                | - Hiệu suất tốt trên nhiều nhiệm vụ.                                        | - Kích thước lớn, cần tài nguyên tính toán cao.                                                | Phân loại văn bản, phân tích cảm xúc, QA.                      |\n",
    "| **DistilBERT**       | ~66M          | ~250                | Tiếng Anh                | - Nhẹ hơn BERT, nhanh hơn ~60%.                                            | - Hiệu suất giảm nhẹ so với BERT.                                                              | Chatbot, phân loại ý định, gợi ý tự động.                      |\n",
    "| **PhoBERT**          | ~135M         | ~500                | Tiếng Việt               | - Được tối ưu hóa cho tiếng Việt.                                           | - Chỉ hỗ trợ tiếng Việt.                                                                       | Phân loại cảm xúc, phân tích ý định tiếng Việt.                |\n",
    "| **XLM-RoBERTa**      | ~125M         | ~550                | Đa ngôn ngữ (100+)       | - Tốt cho các nhiệm vụ đa ngôn ngữ.                                         | - Kích thước lớn, cần nhiều tài nguyên.                                                        | Dịch máy, nhận dạng thực thể (NER), QA.                        |\n",
    "| **BERTweet**         | ~135M         | ~500                | Tiếng Anh                | - Tối ưu cho dữ liệu từ Twitter.                                            | - Chỉ hiệu quả trên dữ liệu không chính thức, ví dụ như Twitter.                              | Phân tích cảm xúc mạng xã hội, nhận dạng chủ đề.               |\n",
    "| **ALBERT**           | ~12M          | ~40                 | Tiếng Anh                | - Nhẹ hơn BERT, nhanh hơn nhiều lần.                                        | - Hiệu suất giảm trên dữ liệu lớn hơn hoặc phức tạp.                                           | Phân tích cảm xúc, gợi ý văn bản.                              |\n",
    "| **ELECTRA**          | ~14M          | ~50                 | Tiếng Anh                | - Huấn luyện nhanh hơn BERT với chi phí thấp hơn.                           | - Hiệu suất không vượt trội trên tất cả các nhiệm vụ.                                          | Phân loại văn bản, phân tích cảm xúc.                          |\n",
    "| **mBERT (Multilingual BERT)** | ~110M         | ~450                | Đa ngôn ngữ (100+)       | - Tốt cho các tác vụ đa ngôn ngữ cơ bản.                                    | - Không được tối ưu hóa cho ngôn ngữ cụ thể.                                                  | Dịch máy, QA, phân tích văn bản đa ngôn ngữ.                   |\n",
    "| **RoBERTa**          | ~125M         | ~550                | Tiếng Anh                | - Cải thiện hiệu suất nhờ huấn luyện với lượng dữ liệu lớn hơn BERT.         | - Kích thước lớn, tốc độ chậm hơn BERT.                                                       | QA, phân tích cú pháp, phân tích văn bản phức tạp.             |\n",
    "| **GPT-based models** | ~175B         | > 70000             | Tiếng Anh, đa ngôn ngữ   | - Tốt cho nhiều nhiệm vụ, bao gồm cả sáng tạo nội dung và phân loại văn bản. | - Cực kỳ nặng, cần GPU mạnh, chi phí huấn luyện và triển khai cao.                            | Sáng tạo nội dung, viết văn bản tự động, chatbot nâng cao.      |\n",
    "\n",
    "### Kết luận:\n",
    "- **Nếu tài nguyên giới hạn:** Sử dụng **DistilBERT** hoặc **ALBERT**.\n",
    "- **Nếu cần xử lý tiếng Việt:** Chọn **PhoBERT**.\n",
    "- **Nếu cần mô hình đa ngôn ngữ:** **XLM-RoBERTa** hoặc **mBERT** là lựa chọn tốt.\n",
    "- **Nếu cần xử lý mạng xã hội:** **BERTweet** phù hợp cho các nguồn dữ liệu như Twitter.\n",
    "- **Nếu yêu cầu hiệu suất cao:** **RoBERTa** hoặc **ELECTRA** có thể là lựa chọn tối ưu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vấn đề cần xử lý - Next step: \n",
    "\n",
    "1. Benchmark chuẩn để có bộ Testing Acc chính xác. \n",
    "2. Train tối ưu model \n",
    "3. Có thể cần tối ưu data, tăng thêm data, Augmentation Data. \n",
    "- 1. Copy câu của robot, chế câu của user => được gấp 2, 3 dữ liệu cho nhãn: fallback và silence. \n",
    "- 2. Augmentation bằng việc THAY ĐỔI NGỮ NGHĨA của câu robot và user. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
